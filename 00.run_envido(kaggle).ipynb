{"metadata":{"colab":{"provenance":[],"collapsed_sections":["fHADhl4_hkYp","FglvzTrXhkYt","kTG_5YDThkYu","vAkTjCfUhkYv"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9076399,"sourceType":"datasetVersion","datasetId":5475460}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **TUIA - Procesamiento de Im√°genes y Visi√≥n por Computadora (IA52)**\n# **Trabajo Pr√°ctico Final**\n### **Ejercicio 4 - Evaluaci√≥n**\n<br>\n\n### *Alumno: Miguel Mussi*\n### *A√±o: 2024*\n\n---------------------\n## **Tabla de contenidos**\n1.   [**Librer√≠as**](#)\n2.   [**Ajustes Iniciales**](#)\n3.   [**Optimizaci√≥n de inferencia**](#)\n4.   [**Inferencia sobre las im√°genes y c√°lculo del envido**](#)\n        1.   [*Inferencia con CPU*](#)\n        2.   [*Inferencia con GPU - Sin TensorRT*](#)\n        3.   [*Inferencia con GPU - Con TensorRT*](#)\n        4.   [*Comparativa de Inferencias*](#)\n5.   [**Guardamos las imagenes con las predicciones**](#)\n6.   [**Escritura del archivo envido.json**](#)\n7.   [**Exportar directorios**](#)","metadata":{"id":"SUKX__a1UgGt"}},{"cell_type":"markdown","source":"## 1. **Librer√≠as**","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"I9JftkdJhkYQ"}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"id":"OeICo45_hkYS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dcbaaca9-f59c-4dfa-ba17-566d80c8518f","execution":{"iopub.status.busy":"2024-07-31T17:17:50.246330Z","iopub.execute_input":"2024-07-31T17:17:50.246613Z","iopub.status.idle":"2024-07-31T17:18:05.896721Z","shell.execute_reply.started":"2024-07-31T17:17:50.246587Z","shell.execute_reply":"2024-07-31T17:18:05.895491Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.2.70-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m552.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.2.70-py3-none-any.whl (862 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m862.6/862.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.2.70 ultralytics-thop-2.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install onnx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjbG0RCXkgCx","outputId":"35ffba4f-d5f1-43c7-92fc-0949c834e401","execution":{"iopub.status.busy":"2024-07-31T17:18:05.906598Z","iopub.execute_input":"2024-07-31T17:18:05.906863Z","iopub.status.idle":"2024-07-31T17:18:18.101190Z","shell.execute_reply.started":"2024-07-31T17:18:05.906834Z","shell.execute_reply":"2024-07-31T17:18:18.100135Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (1.16.1)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from onnx) (1.26.4)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx) (3.20.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport json\nimport torch\nimport shutil\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt","metadata":{"id":"ZxlBx8OXUgGu","execution":{"iopub.status.busy":"2024-07-31T17:18:21.698952Z","iopub.execute_input":"2024-07-31T17:18:21.699633Z","iopub.status.idle":"2024-07-31T17:18:26.252693Z","shell.execute_reply.started":"2024-07-31T17:18:21.699599Z","shell.execute_reply":"2024-07-31T17:18:26.251721Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"Z5wXHxYThkYY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9a7aaec-445b-4934-d60e-7416e7230954"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Mounted at /content/drive\n"}]},{"cell_type":"markdown","source":"## 2. **Ajustes Iniciales**","metadata":{"id":"Kzf_37QPUgGu","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"code","source":"# Nombre del alumno\nstudent_name = 'miguel_mussi'\n\n# Ruta al directorio principal\nmain_path = '/kaggle/input/cv-tp-final/CV_TP_Final'\n\n# Ruta al archivo de pesos\nmodel_path = os.path.join(main_path, 'model/weights/best.pt')\n# model_path_tensor = os.path.join(main_path, '/kaggle/working/model/weights/best.onnx')\nmodel_path_tensor = os.path.join('/kaggle/working', 'best.onnx')\n\n# Ruta al directorio que contiene las imagenes\nimgs_dir = os.path.join(main_path, 'data/eval/images/val')\n\n# Ruta al directorio de destino de las detecciones\nbase_dir = os.path.join('/kaggle/working/data/out/')\ndets_dir = os.path.join(base_dir, student_name)\n\n# Reestablecimiento del directorio de destino (eliminacion)\nif os.path.exists(dets_dir):\n    shutil.rmtree(dets_dir)\nos.makedirs(dets_dir)","metadata":{"id":"LrsYEZXHUgGv","execution":{"iopub.status.busy":"2024-07-31T17:41:40.862781Z","iopub.execute_input":"2024-07-31T17:41:40.863411Z","iopub.status.idle":"2024-07-31T17:41:40.870219Z","shell.execute_reply.started":"2024-07-31T17:41:40.863376Z","shell.execute_reply":"2024-07-31T17:41:40.869255Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Nombre del alumno\nstudent_name = 'miguel_mussi'\n\n# Ruta al directorio principal\nmain_path = '/kaggle/input/cv-tp-final/CV_TP_Final'\n\n# Ruta del directorio de trabajo\nworking_dir = '/kaggle/working/'\n\n# Ruta al archivo de pesos copiado en el directorio de trabajo\nmodel_path_working = os.path.join(working_dir, 'model/weights/best.pt')\n\n# Copiar la carpeta 'model' al directorio de trabajo\nif not os.path.exists(os.path.join(working_dir, 'model')):\n    shutil.copytree(os.path.join(main_path, 'model'), os.path.join(working_dir, 'model'))\n\n# Ruta para guardar el modelo exportado\nmodel_path_tensor = os.path.join(working_dir, 'model/weights/best.onnx')\n\n# Ruta al directorio que contiene las im√°genes\nimgs_dir = os.path.join(main_path, 'data/eval/images/val')\n\n# Ruta al directorio de destino de las detecciones\nbase_dir = os.path.join(working_dir, 'data/out/')\ndets_dir = os.path.join(base_dir, student_name)\n\n# Reestablecimiento del directorio de destino (eliminaci√≥n)\nif os.path.exists(dets_dir):\n    shutil.rmtree(dets_dir)\nos.makedirs(dets_dir)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T18:00:18.734082Z","iopub.execute_input":"2024-07-31T18:00:18.734480Z","iopub.status.idle":"2024-07-31T18:00:18.743151Z","shell.execute_reply.started":"2024-07-31T18:00:18.734449Z","shell.execute_reply":"2024-07-31T18:00:18.742254Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"if os.path.exists('/kaggle/working/model'):\n    shutil.rmtree('/kaggle/working/model')\n# os.makedirs('/kaggle/working/model')","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:58:01.225653Z","iopub.execute_input":"2024-07-31T17:58:01.226350Z","iopub.status.idle":"2024-07-31T17:58:01.246593Z","shell.execute_reply.started":"2024-07-31T17:58:01.226315Z","shell.execute_reply":"2024-07-31T17:58:01.245863Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Seteo de tiempos de ejecuci√≥n\nexecution_time = {'cpu': 0, 'gpu': 0, 'rt': 0}","metadata":{"id":"yu8PD-WRsn2h","execution":{"iopub.status.busy":"2024-07-31T17:21:53.141126Z","iopub.execute_input":"2024-07-31T17:21:53.141814Z","iopub.status.idle":"2024-07-31T17:21:53.146082Z","shell.execute_reply.started":"2024-07-31T17:21:53.141785Z","shell.execute_reply":"2024-07-31T17:21:53.145060Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 3. **Optimizaci√≥n de inferencia**","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"0pBqm9G3hkYd"}},{"cell_type":"code","source":"# Cargamos el modelo\nmodel = YOLO(model_path_working)","metadata":{"id":"m0ucZWDi4uAt","execution":{"iopub.status.busy":"2024-07-31T17:58:11.789911Z","iopub.execute_input":"2024-07-31T17:58:11.790282Z","iopub.status.idle":"2024-07-31T17:58:11.947046Z","shell.execute_reply.started":"2024-07-31T17:58:11.790247Z","shell.execute_reply":"2024-07-31T17:58:11.946056Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Lo exportamos como un tensor para utilizar tensorRT con la GPU\nmodel.export(format='onnx', imgsz=640, dynamic=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"VNAwXVLhDeT7","outputId":"4783bb65-6482-4e2e-c023-93e108231b84","execution":{"iopub.status.busy":"2024-07-31T18:00:27.263083Z","iopub.execute_input":"2024-07-31T18:00:27.263873Z","iopub.status.idle":"2024-07-31T18:00:35.313440Z","shell.execute_reply.started":"2024-07-31T18:00:27.263842Z","shell.execute_reply":"2024-07-31T18:00:35.312306Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.70 üöÄ Python-3.10.13 torch-2.1.2 CPU (Intel Xeon 2.00GHz)\nModel summary (fused): 268 layers, 43,644,387 parameters, 0 gradients, 165.0 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/kaggle/working/model/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 53, 8400) (83.6 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 3.8s, saved as '/kaggle/working/model/weights/best.onnx' (166.6 MB)\n\nExport complete (8.0s)\nResults saved to \u001b[1m/kaggle/working/model/weights\u001b[0m\nPredict:         yolo predict task=detect model=/kaggle/working/model/weights/best.onnx imgsz=640  \nValidate:        yolo val task=detect model=/kaggle/working/model/weights/best.onnx imgsz=640 data=/kaggle/working/dataset.yaml  \nVisualize:       https://netron.app\n","output_type":"stream"},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/model/weights/best.onnx'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Comprobaci√≥n de entorno gr√°fico","metadata":{"id":"YhBmvKuS3e8I"}},{"cell_type":"code","source":"print(torch.cuda.is_available())","metadata":{"id":"MfZDDGtnp7zA","outputId":"c74c43fe-59ba-4187-aa40-c57824f929d9","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-07-31T18:02:30.856771Z","iopub.execute_input":"2024-07-31T18:02:30.857243Z","iopub.status.idle":"2024-07-31T18:02:30.862476Z","shell.execute_reply.started":"2024-07-31T18:02:30.857210Z","shell.execute_reply":"2024-07-31T18:02:30.861469Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(f'Usando el dispositivo: {device}')","metadata":{"id":"SI-9xjbZ4NWE","execution":{"iopub.status.busy":"2024-07-31T17:25:33.490125Z","iopub.execute_input":"2024-07-31T17:25:33.490476Z","iopub.status.idle":"2024-07-31T17:25:33.494757Z","shell.execute_reply.started":"2024-07-31T17:25:33.490449Z","shell.execute_reply":"2024-07-31T17:25:33.493694Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(f'Dispositivo del modelo: {next(model.parameters()).device}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7CgC6KSX4Qki","outputId":"6fe1689f-fe39-4df6-c851-87948e073f1f","execution":{"iopub.status.busy":"2024-07-31T17:25:23.562126Z","iopub.execute_input":"2024-07-31T17:25:23.562599Z","iopub.status.idle":"2024-07-31T17:25:23.567938Z","shell.execute_reply.started":"2024-07-31T17:25:23.562567Z","shell.execute_reply":"2024-07-31T17:25:23.566782Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Dispositivo del modelo: cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4wLIyEkD5-k6","outputId":"ee1717ea-59cc-42c4-f04d-1d4c6ff9113e","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu118\n\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n\nRequirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"}]},{"cell_type":"code","source":"# device_id = 0  # El ID de dispositivo que deseas usar\n# if device_id < torch.cuda.device_count():\n#     device = torch.device(f'cuda:{device_id}')\n# else:\n#     raise AssertionError(\"Invalid device id\")","metadata":{"id":"inEsYn2a5n7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_gpus = torch.cuda.device_count()\nprint(f'N√∫mero de GPUs disponibles: {num_gpus}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLIDDDuT5ZZr","outputId":"b2ad0851-e798-4a95-f8df-5ffa6b7923ce","execution":{"iopub.status.busy":"2024-07-31T18:02:37.210573Z","iopub.execute_input":"2024-07-31T18:02:37.211170Z","iopub.status.idle":"2024-07-31T18:02:37.216059Z","shell.execute_reply.started":"2024-07-31T18:02:37.211135Z","shell.execute_reply":"2024-07-31T18:02:37.214991Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"N√∫mero de GPUs disponibles: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4. **Inferencia sobre las im√°genes y c√°lculo del envido**","metadata":{"id":"MEvz0ZGdUgGw","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"code","source":"def calcular_envido(num1,num2):\n    n1 = int(num1)\n    n2 = int(num2)\n    ret = n1 if n1<10 else 0\n    ret += n2 if n2<10 else 0\n    return ret + 20","metadata":{"id":"lE7E_TxmpTGn","execution":{"iopub.status.busy":"2024-07-31T17:25:56.593100Z","iopub.execute_input":"2024-07-31T17:25:56.593465Z","iopub.status.idle":"2024-07-31T17:25:56.598722Z","shell.execute_reply.started":"2024-07-31T17:25:56.593437Z","shell.execute_reply":"2024-07-31T17:25:56.597530Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### 4.1. *Inferencia con CPU*","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"wY0if1KUhkYn"}},{"cell_type":"code","source":"# Marca de tiempo antes de la inferencia\nstart_time = time.time()\n\n# Cargamos el modelo\ndevice = torch.device('cpu')\nmodel = YOLO(model_path).to(device)\n\n# Ejecutamos la inferencia\nresults = model(imgs_dir, stream=True)\n\n# Diccionario que guardar√° la informaci√≥n para el JSON\ncard_js_file = {}\n\n# Umbral de confianza para las detecciones\ndetection_threshold = 0.5\n\n# Iteramos sobre los resultados (archivos)\nfor result in results:\n    # Obtenemos el nombre del archivo de imagen\n    img_filename = os.path.basename(result.path)\n\n    # Contador de cartas inv√°lidas y envido\n    invalid_cards = 0\n\n    # Diccionario para almacenar los tipos de cartas\n    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n\n    # Obtenemos las cartas detectadas\n    cards = result.cpu()\n\n    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n\n    # Filtrar detecciones con umbral de confianza inferior a 0.45\n    filtered_cards = [box for box in result.boxes if box.conf.item() >= detection_threshold]\n\n    # Procesamos cada carta detectada\n    for card in filtered_cards:\n        # Obtenemos el nombre de la carta\n        # name = filtered_cards.names[int(card.boxes.cls)]\n        name = cards.names[int(card.cls)]\n\n        # Separamos el n√∫mero y el palo de la carta\n        if len(name) == 3:      # (Carta negra. Ejemplo 10E - 11E - 12B )\n            num = name[0] + name[1]  # n√∫mero de la carta negra\n            palo = name[2]           # palo de la carta\n        elif len(name) == 2:                   # (Carta blanca. Ejemplo xO - xC - xE - xB )\n            num = name[0]            # n√∫mero de la carta\n            palo = name[1]           # palo de la carta\n        else:\n            num = name[0]            # n√∫mero del comod√≠n\n            palo = 'N/A'             # palo del comod√≠n\n\n        # Comprobamos si la carta es inv√°lida\n        if num in ['8', '9', 'J']:\n            invalid_cards += 1\n\n        # Agregamos la carta al diccionario correspondiente\n        if palo in card_types:\n            if num not in card_types[palo]:\n                card_types[palo].append(num)\n            else:\n                print(\"Se encontraron cartas repetidas\")\n                invalid_cards += 1\n\n    envido = {}\n\n    # Comprobar si la cantidad de cartas es 3\n    if len(filtered_cards) != 3 or invalid_cards:\n        print('La cantidad de cartas no permite calcular el envido.\\n')\n\n    # 3 cartas en la detecci√≥n\n    else:\n        # Inicializamos la variable palo\n\n        # calculamos el envido\n        # Iteramos en el diccionario - Key = palos / Value: n√∫meros\n        for key, values in card_types.items():\n            envido[key]=0\n            # Dos cartas del mismo palo\n            if len(values) == 1:\n                envido[key] = int(num) if len(num)==1 else 0\n\n            elif len(values) == 2:\n                envido[key] = calcular_envido(values[0],values[1])\n\n            # Tres cartas del mismo palo\n            elif len(values) == 3:\n                print('Mano con Flor.\\n')\n                envido[key] = calcular_envido(values[0],values[1])\n                envido[key] = max(envido[key],calcular_envido(values[0],values[2]))\n                envido[key] = max(envido[key],calcular_envido(values[1],values[2]))\n\n\n    mejor_palo = 'N/A'\n    mejor_punto = 0\n\n    for palo, punto in envido.items():\n        if punto > mejor_punto:\n            mejor_punto=punto\n            mejor_palo = palo\n\n    # Almacenamos los resultados del envido en el diccionario para el JSON\n\n\n    card_js_file[img_filename] = {\n            'total_cards': len(filtered_cards),\n            'cards': card_types,\n            'points': mejor_punto,       # Puntos de envido\n            'figure': mejor_palo          # Palo\n        }\n\n\n# Marca de tiempo despu√©s de la inferencia\nend_time = time.time()\n\n# Calculamos el tiempo de ejecuci√≥n\nexecution_time['cpu'] = end_time - start_time\n\n# Mostramos que dispositivo se esta utilizando y el tiempo de ejecuci√≥n\nif device.type == 'cuda': print('\\nEl modelo est√° utilizando la GPU.')\nelse: print('\\nEl modelo est√° utilizando la CPU.')\n# print(f'Tiempo de ejecuci√≥n: {execution_time['cpu']:.2f} segundos')\nprint(f\"Tiempo de ejecuci√≥n: {execution_time['cpu']:.2f} segundos\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ED5w3buhGJO_","outputId":"0c279c6a-7402-4dcc-932c-d0e800deb3a6","execution":{"iopub.status.busy":"2024-07-31T17:26:51.489640Z","iopub.execute_input":"2024-07-31T17:26:51.490312Z","iopub.status.idle":"2024-07-31T17:27:26.146556Z","shell.execute_reply.started":"2024-07-31T17:26:51.490281Z","shell.execute_reply":"2024-07-31T17:27:26.145864Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\nimage 1/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 960.6ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 2/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 936.6ms\nimage 3/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 947.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 4/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 947.2ms\nimage 5/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 924.7ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 6/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 919.5ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 7/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 916.5ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 8/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 898.6ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 9/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 906.1ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 10/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 920.8ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 11/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 885.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 12/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 926.0ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 13/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 903.9ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 14/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 917.7ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 15/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 914.0ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 16/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 887.5ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 17/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 913.9ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 18/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 921.1ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 19/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 902.7ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 20/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 896.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 21/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 898.7ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 22/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 900.7ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 23/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 911.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 24/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 918.7ms\nMano con Flor.\n\nimage 25/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 913.1ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 26/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 933.6ms\nSe encontraron cartas repetidas\nLa cantidad de cartas no permite calcular el envido.\n\nimage 27/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 909.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 28/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 968.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 29/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 950.9ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 30/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 942.2ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 31/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 947.0ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 32/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 927.3ms\nSpeed: 3.5ms preprocess, 920.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n\nEl modelo est√° utilizando la CPU.\nTiempo de ejecuci√≥n: 34.64 segundos\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 4.2. *Inferencia con GPU - Sin TensorRT*","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"fHADhl4_hkYp"}},{"cell_type":"code","source":"# Marca de tiempo antes de la inferencia\nstart_time = time.time()\n\n# Cargamos el modelo\n# device = torch.device('cuda:0')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = YOLO(model_path).to(device)\n\n# Ejecutamos la inferencia\nresults = model(imgs_dir, stream=True)\n\n# Diccionario que guardar√° la informaci√≥n para el JSON\ncard_js_file = {}\n\n# Umbral de confianza para las detecciones\ndetection_threshold = 0.5\n\n# Iteramos sobre los resultados (archivos)\nfor result in results:\n    # Obtenemos el nombre del archivo de imagen\n    img_filename = os.path.basename(result.path)\n\n    # Contador de cartas inv√°lidas y envido\n    invalid_cards = 0\n\n    # Diccionario para almacenar los tipos de cartas\n    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n\n    # Obtenemos las cartas detectadas\n    cards = result.cpu()\n\n    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n\n    # Filtrar detecciones con umbral de confianza inferior a 0.45\n    filtered_cards = [box for box in result.boxes if box.conf.item() >= detection_threshold]\n\n    # Procesamos cada carta detectada\n    for card in filtered_cards:\n        # Obtenemos el nombre de la carta\n        # name = filtered_cards.names[int(card.boxes.cls)]\n        name = cards.names[int(card.cls)]\n\n        # Separamos el n√∫mero y el palo de la carta\n        if len(name) == 3:      # (Carta negra. Ejemplo 10E - 11E - 12B )\n            num = name[0] + name[1]  # n√∫mero de la carta negra\n            palo = name[2]           # palo de la carta\n        elif len(name) == 2:                   # (Carta blanca. Ejemplo xO - xC - xE - xB )\n            num = name[0]            # n√∫mero de la carta\n            palo = name[1]           # palo de la carta\n        else:\n            num = name[0]            # n√∫mero del comod√≠n\n            palo = 'N/A'             # palo del comod√≠n\n\n        # Comprobamos si la carta es inv√°lida\n        if num in ['8', '9', 'J']:\n            invalid_cards += 1\n\n        # Agregamos la carta al diccionario correspondiente\n        if palo in card_types:\n            if num not in card_types[palo]:\n                card_types[palo].append(num)\n            else:\n                print(\"Se encontraron cartas repetidas\")\n                invalid_cards += 1\n\n    envido = {}\n\n    # Comprobar si la cantidad de cartas es 3\n    if len(filtered_cards) != 3 or invalid_cards:\n        print('La cantidad de cartas no permite calcular el envido.\\n')\n\n    # 3 cartas en la detecci√≥n\n    else:\n        # Inicializamos la variable palo\n\n        # calculamos el envido\n        # Iteramos en el diccionario - Key = palos / Value: n√∫meros\n        for key, values in card_types.items():\n            envido[key]=0\n            # Dos cartas del mismo palo\n            if len(values) == 1:\n                envido[key] = int(num) if len(num)==1 else 0\n\n            elif len(values) == 2:\n                envido[key] = calcular_envido(values[0],values[1])\n\n            # Tres cartas del mismo palo\n            elif len(values) == 3:\n                print('Mano con Flor.\\n')\n                envido[key] = calcular_envido(values[0],values[1])\n                envido[key] = max(envido[key],calcular_envido(values[0],values[2]))\n                envido[key] = max(envido[key],calcular_envido(values[1],values[2]))\n\n\n    mejor_palo = 'N/A'\n    mejor_punto = 0\n\n    for palo, punto in envido.items():\n        if punto > mejor_punto:\n            mejor_punto=punto\n            mejor_palo = palo\n\n    # Almacenamos los resultados del envido en el diccionario para el JSON\n\n\n    card_js_file[img_filename] = {\n            'total_cards': len(filtered_cards),\n            'cards': card_types,\n            'points': mejor_punto,       # Puntos de envido\n            'figure': mejor_palo          # Palo\n        }\n\n\n# Marca de tiempo despu√©s de la inferencia\nend_time = time.time()\n\n# Calculamos el tiempo de ejecuci√≥n\nexecution_time['gpu'] = end_time - start_time\n\n# Mostramos que dispositivo se esta utilizando y el tiempo de ejecuci√≥n\nif device.type == 'cuda': print('\\nEl modelo est√° utilizando la GPU.')\nelse: print('\\nEl modelo est√° utilizando la CPU.')\n# print(f'Tiempo de ejecuci√≥n: {execution_time['cpu']:.2f} segundos')\nprint(f\"Tiempo de ejecuci√≥n: {execution_time['gpu']:.2f} segundos\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwH2UlYOu4uZ","outputId":"5d083849-eee8-44fe-c9ba-d94bb9837132","execution":{"iopub.status.busy":"2024-07-31T17:30:25.840084Z","iopub.execute_input":"2024-07-31T17:30:25.840510Z","iopub.status.idle":"2024-07-31T17:30:32.132729Z","shell.execute_reply.started":"2024-07-31T17:30:25.840478Z","shell.execute_reply":"2024-07-31T17:30:32.131858Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\nimage 1/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 48.1ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 2/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 47.3ms\nimage 3/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 4/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 47.2ms\nimage 5/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 6/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 7/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 8/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 9/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 47.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 10/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 11/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 12/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 13/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 14/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 15/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 16/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 17/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 18/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 19/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 47.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 20/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 47.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 21/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 47.4ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 22/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 23/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 24/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 47.3ms\nMano con Flor.\n\nimage 25/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 26/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 47.3ms\nSe encontraron cartas repetidas\nLa cantidad de cartas no permite calcular el envido.\n\nimage 27/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 28/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 29/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 30/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 47.3ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 31/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 48.6ms\nLa cantidad de cartas no permite calcular el envido.\n\nimage 32/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 44.4ms\nSpeed: 3.2ms preprocess, 47.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n\nEl modelo est√° utilizando la GPU.\nTiempo de ejecuci√≥n: 6.27 segundos\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 4.3. *Inferencia con GPU - Con TensorRT*","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"FglvzTrXhkYt"}},{"cell_type":"code","source":"# Cargamos el modelo\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Marca de tiempo antes de la inferencia\nstart_time = time.time()\n\n# Ejecutamos la inferencia\nresults = YOLO(model_path_tensor).predict(source=imgs_dir, device=device)\n\n# Diccionario que guardar√° la informaci√≥n para el JSON\ncard_js_file = {}\n\n# Umbral de confianza para las detecciones\ndetection_threshold = 0.5\n\n# Iteramos sobre los resultados (archivos)\nfor result in results:\n    # Obtenemos el nombre del archivo de imagen\n    img_filename = os.path.basename(result.path)\n\n    # Contador de cartas inv√°lidas y envido\n    invalid_cards = 0\n\n    # Diccionario para almacenar los tipos de cartas\n    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n\n    # Obtenemos las cartas detectadas\n    cards = result.cpu()\n\n    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n\n    # Filtrar detecciones con umbral de confianza inferior a 0.45\n    filtered_cards = [box for box in result.boxes if box.conf.item() >= detection_threshold]\n\n    # Procesamos cada carta detectada\n    for card in filtered_cards:\n        # Obtenemos el nombre de la carta\n        # name = filtered_cards.names[int(card.boxes.cls)]\n        name = cards.names[int(card.cls)]\n\n        # Separamos el n√∫mero y el palo de la carta\n        if len(name) == 3:      # (Carta negra. Ejemplo 10E - 11E - 12B )\n            num = name[0] + name[1]  # n√∫mero de la carta negra\n            palo = name[2]           # palo de la carta\n        elif len(name) == 2:                   # (Carta blanca. Ejemplo xO - xC - xE - xB )\n            num = name[0]            # n√∫mero de la carta\n            palo = name[1]           # palo de la carta\n        else:\n            num = name[0]            # n√∫mero del comod√≠n\n            palo = 'N/A'             # palo del comod√≠n\n\n        # Comprobamos si la carta es inv√°lida\n        if num in ['8', '9', 'J']:\n            invalid_cards += 1\n\n        # Agregamos la carta al diccionario correspondiente\n        if palo in card_types:\n            if num not in card_types[palo]:\n                card_types[palo].append(num)\n            else:\n                print(\"Se encontraron cartas repetidas\")\n                invalid_cards += 1\n\n    envido = {}\n\n    # Comprobar si la cantidad de cartas es 3\n    if len(filtered_cards) != 3 or invalid_cards:\n        print('La cantidad de cartas no permite calcular el envido.\\n')\n\n    # 3 cartas en la detecci√≥n\n    else:\n        # Inicializamos la variable palo\n\n        # calculamos el envido\n        # Iteramos en el diccionario - Key = palos / Value: n√∫meros\n        for key, values in card_types.items():\n            envido[key]=0\n            # Dos cartas del mismo palo\n            if len(values) == 1:\n                envido[key] = int(num) if len(num)==1 else 0\n\n            elif len(values) == 2:\n                envido[key] = calcular_envido(values[0],values[1])\n\n            # Tres cartas del mismo palo\n            elif len(values) == 3:\n                print('Mano con Flor.\\n')\n                envido[key] = calcular_envido(values[0],values[1])\n                envido[key] = max(envido[key],calcular_envido(values[0],values[2]))\n                envido[key] = max(envido[key],calcular_envido(values[1],values[2]))\n\n\n    mejor_palo = 'N/A'\n    mejor_punto = 0\n\n    for palo, punto in envido.items():\n        if punto > mejor_punto:\n            mejor_punto=punto\n            mejor_palo = palo\n\n    # Almacenamos los resultados del envido en el diccionario para el JSON\n\n\n    card_js_file[img_filename] = {\n            'total_cards': len(filtered_cards),\n            'cards': card_types,\n            'points': mejor_punto,       # Puntos de envido\n            'figure': mejor_palo          # Palo\n        }\n\n\n# Marca de tiempo despu√©s de la inferencia\nend_time = time.time()\n\n# Calculamos el tiempo de ejecuci√≥n\nexecution_time['rt'] = end_time - start_time\n\n# Mostramos que dispositivo se esta utilizando y el tiempo de ejecuci√≥n\nif device.type == 'cuda': print('\\nEl modelo est√° utilizando la GPU.')\nelse: print('\\nEl modelo est√° utilizando la CPU.')\n# print(f'Tiempo de ejecuci√≥n: {execution_time['cpu']:.2f} segundos')\nprint(f\"Tiempo de ejecuci√≥n: {execution_time['rt']:.2f} segundos\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFFsNtYdwSOm","outputId":"fc6393ff-fc7d-415d-d7c6-899eefff6a3d","execution":{"iopub.status.busy":"2024-07-31T18:11:56.179159Z","iopub.execute_input":"2024-07-31T18:11:56.179521Z","iopub.status.idle":"2024-07-31T18:12:28.824208Z","shell.execute_reply.started":"2024-07-31T18:11:56.179485Z","shell.execute_reply":"2024-07-31T18:12:28.823299Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\nLoading /kaggle/working/model/weights/best.onnx for ONNX Runtime inference...\n\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;31m2024-07-31 18:11:56.299308943 [E:onnxruntime:Default, provider_bridge_ort.cc:1745 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n\u001b[m\n\u001b[0;93m2024-07-31 18:11:56.299339532 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:895 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Please reference https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirementsto ensure all dependencies are met.\u001b[m\n","output_type":"stream"},{"name":"stdout","text":"image 1/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x640 1 4O, 1 11C, 788.8ms\nimage 2/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x640 1 1C, 1 2B, 1 5C, 823.2ms\nimage 3/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x640 1 1C, 1 2B, 812.0ms\nimage 4/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x640 1 3B, 1 6B, 1 7E, 795.0ms\nimage 5/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x640 1 3B, 1 6B, 1 7E, 1 J, 785.2ms\nimage 6/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x640 1 6B, 1 7E, 783.6ms\nimage 7/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x640 1 3B, 790.9ms\nimage 8/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x640 1 8O, 1 9O, 780.4ms\nimage 9/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x640 1 3O, 1 8O, 1 9O, 786.3ms\nimage 10/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x640 1 1O, 1 10C, 808.5ms\nimage 11/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x640 1 1O, 781.1ms\nimage 12/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x640 1 6E, 1 8B, 1 9B, 777.5ms\nimage 13/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x640 1 8B, 834.9ms\nimage 14/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x640 1 8C, 1 9C, 1 9E, 786.7ms\nimage 15/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x640 1 3E, 1 4E, 782.0ms\nimage 16/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x640 1 3E, 1190.3ms\nimage 17/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x640 1 11E, 1 12E, 1005.7ms\nimage 18/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x640 1 5E, 1 11O, 784.9ms\nimage 19/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x640 1 4O, 1 12B, 779.8ms\nimage 20/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x640 1 4O, 1 10E, 789.0ms\nimage 21/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x640 1 2C, 783.0ms\nimage 22/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x640 1 1E, 1 6C, 833.7ms\nimage 23/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x640 1 2O, 1 7C, 791.1ms\nimage 24/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x640 1 1B, 1 4B, 1 7B, 788.6ms\nimage 25/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x640 1 7O, 1 10B, 769.1ms\nimage 26/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x640 2 5Os, 1 10B, 768.8ms\nimage 27/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x640 2 5Os, 1 6O, 1 10B, 771.6ms\nimage 28/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x640 1 7C, 1 12O, 780.3ms\nimage 29/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x640 1 6O, 780.2ms\nimage 30/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x640 1 1B, 1 3C, 787.1ms\nimage 31/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 640x640 1 5B, 786.3ms\nimage 32/32 /kaggle/input/cv-tp-final/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x640 1 10O, 1 11B, 1 12C, 770.0ms\nSpeed: 3.4ms preprocess, 808.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nMano con Flor.\n\nLa cantidad de cartas no permite calcular el envido.\n\nSe encontraron cartas repetidas\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\nLa cantidad de cartas no permite calcular el envido.\n\n\nEl modelo est√° utilizando la GPU.\nTiempo de ejecuci√≥n: 32.63 segundos\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 4.4. *Comparativa de Inferencias*","metadata":{"id":"HaokfCNTtD_P"}},{"cell_type":"code","source":"# Comparaci√≥n de los tiempos de ejecuci√≥n\nprint(\"Comparaci√≥n de Tiempos de Ejecuci√≥n:\")\nprint(f\"Tiempo de ejecuci√≥n (CPU): {execution_time['cpu']:.2f} segundos\")\nprint(f\"Tiempo de ejecuci√≥n (GPU): {execution_time['gpu']:.2f} segundos\")\nprint(f\"Tiempo de ejecuci√≥n (TensorRT): {execution_time['rt']:.2f} segundos\")","metadata":{"id":"hLdMESYatKC3","outputId":"a009291b-e2ac-43dd-e9bd-aae841f25e1e","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-07-31T18:12:37.457449Z","iopub.execute_input":"2024-07-31T18:12:37.458052Z","iopub.status.idle":"2024-07-31T18:12:37.462867Z","shell.execute_reply.started":"2024-07-31T18:12:37.458022Z","shell.execute_reply":"2024-07-31T18:12:37.461953Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Comparaci√≥n de Tiempos de Ejecuci√≥n:\nTiempo de ejecuci√≥n (CPU): 34.64 segundos\nTiempo de ejecuci√≥n (GPU): 6.27 segundos\nTiempo de ejecuci√≥n (TensorRT): 32.63 segundos\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 5. **Guardamos las imagenes con las predicciones**","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"kTG_5YDThkYu"}},{"cell_type":"code","source":"# Cargamos el modelo\n# model = YOLO(model_path)              # Con CPU\nmodel = YOLO(model_path).to(device)     # Con GPU (sin TensorRT)\n# model = YOLO(model_path_tensor)       # Con GPU (con TensorRT)\n\n# Ejecutamos la inferencia\nresults = model(imgs_dir, stream=True)\n\n# Directorio donde van a ir las deteciones\ndetection_dir = f'{base_dir}/detections/'\n\n# Creamos el directorio si no existe\nos.makedirs(detection_dir, exist_ok=True)\n\n# Iteramos sobre los resultados\nfor result in results:\n    # Obtenemos el nombre del archivo de imagen\n    img_filename = os.path.basename(result.path)\n\n    # Guardamos la detecci√≥n\n    result.save(filename=f'{detection_dir}/{img_filename}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjIxN-B3FBTK","outputId":"2801906a-b85e-4193-bbc5-be38ea01e27c","jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\nimage 1/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 1805.6ms\n\nimage 2/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 1304.6ms\n\nimage 3/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 1376.4ms\n\nimage 4/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1357.8ms\n\nimage 5/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 1363.4ms\n\nimage 6/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 1334.7ms\n\nimage 7/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 1530.4ms\n\nimage 8/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 1962.9ms\n\nimage 9/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 1728.0ms\n\nimage 10/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 1383.8ms\n\nimage 11/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 1274.4ms\n\nimage 12/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 1267.8ms\n\nimage 13/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 1309.7ms\n\nimage 14/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 1302.1ms\n\nimage 15/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 1334.6ms\n\nimage 16/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 1898.2ms\n\nimage 17/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 1928.7ms\n\nimage 18/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 1320.6ms\n\nimage 19/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 1315.7ms\n\nimage 20/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 1325.5ms\n\nimage 21/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 1312.2ms\n\nimage 22/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 1302.8ms\n\nimage 23/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 1319.3ms\n\nimage 24/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 1888.1ms\n\nimage 25/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 1919.9ms\n\nimage 26/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 1328.3ms\n\nimage 27/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 1290.0ms\n\nimage 28/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 1305.3ms\n\nimage 29/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 1285.0ms\n\nimage 30/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 1272.7ms\n\nimage 31/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 1312.3ms\n\nimage 32/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 1656.7ms\n\nSpeed: 4.2ms preprocess, 1456.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n"}]},{"cell_type":"markdown","source":"## 6. **Escritura del archivo envido.json**","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"vAkTjCfUhkYv"}},{"cell_type":"code","source":"with open(os.path.join(dets_dir, 'envido.json'), 'w') as jf:\n    json.dump(card_js_file, jf, indent=4)","metadata":{"id":"wc50R4WLhkYv","execution":{"iopub.status.busy":"2024-07-31T18:13:44.677957Z","iopub.execute_input":"2024-07-31T18:13:44.678736Z","iopub.status.idle":"2024-07-31T18:13:44.684755Z","shell.execute_reply.started":"2024-07-31T18:13:44.678703Z","shell.execute_reply":"2024-07-31T18:13:44.683809Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"## 7. **Exportar directorios**","metadata":{"id":"TInWEVkuhqDB"}},{"cell_type":"code","source":"# Especifica la carpeta a comprimir y el nombre del archivo zip\nfolder_path = '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections'\n\nzip_name = '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections.zip'\n\n# Crear el archivo zip\nshutil.make_archive(zip_name.replace('.zip', ''), 'zip', folder_path)\n\nprint(f\"Archivo zip creado: {zip_name}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:07:07.173550Z","iopub.execute_input":"2024-07-28T11:07:07.174541Z","iopub.status.idle":"2024-07-28T11:07:10.239276Z","shell.execute_reply.started":"2024-07-28T11:07:07.174505Z","shell.execute_reply":"2024-07-28T11:07:10.238323Z"},"id":"46C89uqlhqDD","outputId":"272d4909-8ca1-4e13-8727-3907e135c1e2","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":"Archivo zip creado: /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections.zip\n"}]},{"cell_type":"code","source":"# Eliminar un archivo\nos.remove('/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections.zip')\nprint(\"Eliminaci√≥n completa!\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:12:05.215285Z","iopub.execute_input":"2024-07-28T11:12:05.216362Z","iopub.status.idle":"2024-07-28T11:12:05.300249Z","shell.execute_reply.started":"2024-07-28T11:12:05.216325Z","shell.execute_reply":"2024-07-28T11:12:05.299310Z"},"id":"DpfCoSY6hqDE","outputId":"7c7bede8-9f28-4681-edb9-24607a98d706","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":"Eliminaci√≥n completa!\n"}]},{"cell_type":"code","source":"# Eliminar un directorio y todo su contenido\nshutil.rmtree('/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections')\nprint(\"Eliminaci√≥n completa!\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:16:32.995292Z","iopub.execute_input":"2024-07-28T11:16:32.995705Z","iopub.status.idle":"2024-07-28T11:16:33.033287Z","shell.execute_reply.started":"2024-07-28T11:16:32.995674Z","shell.execute_reply":"2024-07-28T11:16:33.032382Z"},"id":"018JUVNUhqDF","outputId":"71a16335-c8fa-468a-de6e-a0b93b9cf2c8","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Eliminaci√≥n completa!\n","output_type":"stream"}]}]}