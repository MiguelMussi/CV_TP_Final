{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUKX__a1UgGt"
      },
      "source": [
        "# **TUIA - Procesamiento de Imágenes y Visión por Computadora (IA52)**\n",
        "# **Trabajo Práctico Final**\n",
        "### **Ejercicio 4 - Evaluación**\n",
        "<br>\n",
        "\n",
        "### *Alumno: Miguel Mussi*\n",
        "### *Año: 2024*\n",
        "\n",
        "---------------------\n",
        "## **Tabla de contenidos**\n",
        "1.   [**Librerías**](#)\n",
        "2.   [**Ajustes Iniciales**](#)\n",
        "3.   [**Optimización de inferencia**](#)\n",
        "4.   [**Inferencia sobre las imágenes y cálculo del envido**](#)\n",
        "        1.   [*Inferencia con CPU*](#)\n",
        "        2.   [*Inferencia con GPU - Sin TensorRT*](#)\n",
        "        3.   [*Inferencia con GPU - Con TensorRT*](#)\n",
        "        4.   [*Comparativa de Inferencias*](#)\n",
        "5.   [**Guardamos las imagenes con las predicciones**](#)\n",
        "6.   [**Escritura del archivo envido.json**](#)\n",
        "7.   [**Exportar directorios**](#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "I9JftkdJhkYQ"
      },
      "source": [
        "## 1. **Librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OeICo45_hkYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea89411d-dd8f-451c-8fec-a4663652d9b2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.70)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjbG0RCXkgCx",
        "outputId": "35ffba4f-d5f1-43c7-92fc-0949c834e401",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZxlBx8OXUgGu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z5wXHxYThkYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28a3703-a1f4-45ca-9584-5805139ab4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzf_37QPUgGu",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 2. **Ajustes Iniciales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LrsYEZXHUgGv"
      },
      "outputs": [],
      "source": [
        "# Nombre del alumno\n",
        "student_name = 'miguel_mussi'\n",
        "\n",
        "# Ruta al directorio principal\n",
        "main_path = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final'\n",
        "\n",
        "# Ruta al archivo de pesos\n",
        "model_path = os.path.join(main_path, 'model/weights/best.pt')\n",
        "model_path_tensor = os.path.join(main_path, 'model/weights/best.onnx')\n",
        "\n",
        "# Ruta al directorio que contiene las imagenes\n",
        "imgs_dir = os.path.join(main_path, 'data/eval/images/val')\n",
        "\n",
        "# Ruta al directorio de destino de las detecciones\n",
        "base_dir = os.path.join(main_path, 'data/out')\n",
        "dets_dir = os.path.join(base_dir, student_name)\n",
        "\n",
        "# Reestablecimiento del directorio de destino (eliminacion)\n",
        "if os.path.exists(dets_dir):\n",
        "    shutil.rmtree(dets_dir)\n",
        "os.makedirs(dets_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seteo de tiempos de ejecución\n",
        "execution_time = {'cpu': 0, 'gpu': 0, 'rt': 0}"
      ],
      "metadata": {
        "id": "yu8PD-WRsn2h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0pBqm9G3hkYd"
      },
      "source": [
        "## 3. **Optimización de inferencia**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "model = YOLO(model_path)"
      ],
      "metadata": {
        "id": "m0ucZWDi4uAt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo exportamos como un tensor para utilizar tensorRT con la GPU\n",
        "model.export(format='onnx', imgsz=640, dynamic=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VNAwXVLhDeT7",
        "outputId": "4783bb65-6482-4e2e-c023-93e108231b84",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.70 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.30GHz)\n",
            "Model summary (fused): 268 layers, 43,644,387 parameters, 0 gradients, 165.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 53, 8400) (83.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 15.1s, saved as '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx' (166.6 MB)\n",
            "\n",
            "Export complete (23.8s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx imgsz=640 data=/kaggle/working/dataset.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comprobación de entorno gráfico"
      ],
      "metadata": {
        "id": "YhBmvKuS3e8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "MfZDDGtnp7zA",
        "outputId": "c74c43fe-59ba-4187-aa40-c57824f929d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Usando el dispositivo: {device}')"
      ],
      "metadata": {
        "id": "SI-9xjbZ4NWE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Dispositivo del modelo: {next(model.parameters()).device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CgC6KSX4Qki",
        "outputId": "6fe1689f-fe39-4df6-c851-87948e073f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo del modelo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wLIyEkD5-k6",
        "outputId": "ee1717ea-59cc-42c4-f04d-1d4c6ff9113e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device_id = 0  # El ID de dispositivo que deseas usar\n",
        "# if device_id < torch.cuda.device_count():\n",
        "#     device = torch.device(f'cuda:{device_id}')\n",
        "# else:\n",
        "#     raise AssertionError(\"Invalid device id\")"
      ],
      "metadata": {
        "id": "inEsYn2a5n7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_gpus = torch.cuda.device_count()\n",
        "print(f'Número de GPUs disponibles: {num_gpus}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLIDDDuT5ZZr",
        "outputId": "b2ad0851-e798-4a95-f8df-5ffa6b7923ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de GPUs disponibles: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEvz0ZGdUgGw",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 4. **Inferencia sobre las imágenes y cálculo del envido**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "wY0if1KUhkYn"
      },
      "source": [
        "### 4.1. *Inferencia con CPU*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### V0"
      ],
      "metadata": {
        "id": "NC5B2QM5yi-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_envido(num1,num2):\n",
        "    n1 = int(num1)\n",
        "    n2 = int(num2)\n",
        "    ret = n1 if n1<10 else 0\n",
        "    ret += n2 if n2<10 else 0\n",
        "    return ret + 20\n",
        "\n",
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cpu')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Umbral de confianza para las detecciones\n",
        "detection_threshold = 0.5\n",
        "\n",
        "# Iteramos sobre los resultados (archivos)\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Filtrar detecciones con umbral de confianza inferior a 0.45\n",
        "    filtered_cards = [box for box in result.boxes if box.conf.item() >= detection_threshold]\n",
        "\n",
        "    # Procesamos cada carta detectada\n",
        "    for card in filtered_cards:\n",
        "        # Obtenemos el nombre de la carta\n",
        "        # name = filtered_cards.names[int(card.boxes.cls)]\n",
        "        name = cards.names[int(card.cls)]\n",
        "\n",
        "        # Separamos el número y el palo de la carta\n",
        "        if len(name) == 3:      # (Carta negra. Ejemplo 10E - 11E - 12B )\n",
        "            num = name[0] + name[1]  # número de la carta negra\n",
        "            palo = name[2]           # palo de la carta\n",
        "        elif len(name) == 2:                   # (Carta blanca. Ejemplo xO - xC - xE - xB )\n",
        "            num = name[0]            # número de la carta\n",
        "            palo = name[1]           # palo de la carta\n",
        "        else:\n",
        "            num = name[0]            # número del comodín\n",
        "            palo = 'N/A'             # palo del comodín\n",
        "\n",
        "        # Comprobamos si la carta es inválida\n",
        "        if num in ['8', '9', 'J']:\n",
        "            invalid_cards += 1\n",
        "\n",
        "        # Agregamos la carta al diccionario correspondiente\n",
        "        if palo in card_types:\n",
        "            card_types[palo].append(num)\n",
        "\n",
        "    envido = {}\n",
        "\n",
        "    # Comprobar si la cantidad de cartas es 3\n",
        "    if len(filtered_cards) != 3 or invalid_cards:\n",
        "        print('La cantidad de cartas no permite calcular el envido.\\n')\n",
        "\n",
        "    # 3 cartas en la detección\n",
        "    else:\n",
        "        # Inicializamos la variable palo\n",
        "\n",
        "        # calculamos el envido\n",
        "        # Iteramos en el diccionario - Key = palos / Value: números\n",
        "        for key, values in card_types.items():\n",
        "            envido[key]=0\n",
        "            # Dos cartas del mismo palo\n",
        "            if len(values) == 1:\n",
        "                envido[key] = int(num) if len(num)==1 else 0\n",
        "\n",
        "            elif len(values) == 2:\n",
        "                envido[key] = calcular_envido(values[0],values[1])\n",
        "\n",
        "            # Tres cartas del mismo palo\n",
        "            elif len(values) == 3:\n",
        "                print('Mano con Flor.\\n')\n",
        "                envido[key] = calcular_envido(values[0],values[1])\n",
        "                envido[key] = max(envido[key],calcular_envido(values[0],values[2]))\n",
        "                envido[key] = max(envido[key],calcular_envido(values[1],values[2]))\n",
        "\n",
        "\n",
        "    mejor_palo = 'N/A'\n",
        "    mejor_punto = 0\n",
        "\n",
        "    for palo, punto in envido.items():\n",
        "        if punto > mejor_punto:\n",
        "            mejor_punto=punto\n",
        "            mejor_palo = palo\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "\n",
        "\n",
        "    card_js_file[img_filename] = {\n",
        "            'total_cards': len(filtered_cards),\n",
        "            'cards': card_types,\n",
        "            'points': mejor_punto,       # Puntos de envido\n",
        "            'figure': mejor_palo          # Palo\n",
        "        }\n",
        "\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time['cpu'] = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "# print(f'Tiempo de ejecución: {execution_time['cpu']:.2f} segundos')\n",
        "print(f\"Tiempo de ejecución: {execution_time['cpu']:.2f} segundos\")"
      ],
      "metadata": {
        "id": "ED5w3buhGJO_",
        "outputId": "62b7b1d8-ba17-412f-c844-eabfa88356e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 3181.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 3497.8ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 2474.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 2454.9ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 2481.9ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 3290.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 3291.7ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 2486.1ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 2468.1ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 2458.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 3617.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 3036.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 2391.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 2478.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 2406.9ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 3548.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 3081.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 2464.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 2453.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 2380.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 3587.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 2945.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 2400.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 2437.2ms\n",
            "Mano con Flor.\n",
            "\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 2430.7ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 3632.5ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 2979.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 2422.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 2376.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 2482.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 3728.7ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 2913.0ms\n",
            "Speed: 4.9ms preprocess, 2821.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "El modelo está utilizando la CPU.\n",
            "Tiempo de ejecución: 98.54 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cpu')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Umbral de confianza para las detecciones\n",
        "detection_threshold = 0.5\n",
        "\n",
        "# Iteramos sobre los resultados (archivos)\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Filtrar detecciones con umbral de confianza inferior a 0.45\n",
        "    filtered_cards = [box for box in result.boxes if box.conf.item() >= detection_threshold]\n",
        "\n",
        "    # Procesamos cada carta detectada\n",
        "    for card in filtered_cards:\n",
        "        # Obtenemos el nombre de la carta\n",
        "        # name = filtered_cards.names[int(card.boxes.cls)]\n",
        "        name = cards.names[int(card.cls)]\n",
        "\n",
        "        # Separamos el número y el palo de la carta\n",
        "        if len(name) == 3:      # (Carta negra. Ejemplo 10E - 11E - 12B )\n",
        "            num = name[0] + name[1]  # número de la carta negra\n",
        "            palo = name[2]           # palo de la carta\n",
        "        elif len(name) == 2:                   # (Carta blanca. Ejemplo xO - xC - xE - xB )\n",
        "            num = name[0]            # número de la carta\n",
        "            palo = name[1]           # palo de la carta\n",
        "        else:\n",
        "            num = name[0]            # número del comodín\n",
        "            palo = 'N/A'             # palo del comodín\n",
        "\n",
        "        # Comprobamos si la carta es inválida\n",
        "        if num in ['8', '9', 'J']:\n",
        "            invalid_cards += 1\n",
        "\n",
        "        # Agregamos la carta al diccionario correspondiente\n",
        "        if palo in card_types:\n",
        "            card_types[palo].append(num)\n",
        "\n",
        "\n",
        "    # Comprobar si la cantidad de cartas es 3\n",
        "    if len(filtered_cards) != 3 or invalid_cards:\n",
        "        print('La cantidad de cartas no permite calcular el envido.\\n')\n",
        "        envido = 0  # Aseguramos que envido tenga un valor\n",
        "        palo = 'N/A'  # Aseguramos que palo tenga un valor\n",
        "\n",
        "    # 3 cartas en la detección\n",
        "    else:\n",
        "        # Inicializamos la variable palo\n",
        "        palo = 'N/A'\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "            envido = 0\n",
        "            palo = 'N/A'\n",
        "\n",
        "        # Si no hay cartas inválidas, calculamos el envido\n",
        "        else:\n",
        "            # Iteramos en el diccionario - Key = palos / Value: números\n",
        "            for key, value in card_types.items():\n",
        "\n",
        "                # Dos cartas del mismo palo\n",
        "                if len(value) == 2:\n",
        "                    palo = key\n",
        "                    for num in value:\n",
        "                            if num not in ['10', '11', '12']:\n",
        "                                envido += int(num)\n",
        "\n",
        "                # Tres cartas del mismo palo\n",
        "                elif len(value) == 3:\n",
        "                        print('Mano con Flor.\\n')\n",
        "                        palo = key\n",
        "                        filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "\n",
        "                        # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                        if len(filtered_values) >= 2:\n",
        "                            largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "                            for num in largest_values:\n",
        "                                envido += int(num)\n",
        "                        elif len(filtered_values) == 1:\n",
        "                            envido += int(filtered_values[0])\n",
        "                        else:\n",
        "                            envido = 20     # Valor trivial ya declarado\n",
        "                else:\n",
        "                    envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido >= 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,       # Puntos de envido\n",
        "            'figure': palo          # Palo\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time['cpu'] = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "# print(f'Tiempo de ejecución: {execution_time['cpu']:.2f} segundos')\n",
        "print(f\"Tiempo de ejecución: {execution_time['cpu']:.2f} segundos\")"
      ],
      "metadata": {
        "id": "wvNrpsDcfkxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### v1"
      ],
      "metadata": {
        "id": "pfeVxNfSyfRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cpu')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Iteramos sobre los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "        envido = 0\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,       # Puntos de envido\n",
        "            'figure': type          # Palo\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_cpu = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_cpu:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXn2DkgfEcQf",
        "outputId": "aa1e7ca3-73fd-4cfd-8d34-dde0091c3d37"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 2500.0ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 2379.1ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 2637.6ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 3789.7ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 2980.7ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 2417.4ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 2475.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 2476.8ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 3946.9ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 2733.6ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 2433.5ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 2466.9ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 2524.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 3955.6ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 2554.3ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 2514.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 2527.4ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 2679.8ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 3965.1ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 2488.2ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 2501.2ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 2526.7ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 3158.7ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 3657.7ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 2354.2ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 2414.9ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 2452.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 3286.4ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 3489.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 2459.0ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 2334.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 2463.8ms\n",
            "Speed: 4.7ms preprocess, 2798.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "El modelo está utilizando la CPU.\n",
            "Tiempo de ejecución: 98.72 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "fHADhl4_hkYp"
      },
      "source": [
        "### 4.2. *Inferencia con GPU - Sin TensorRT*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### V0"
      ],
      "metadata": {
        "id": "Dx_Q5ZYVu3Pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "# device = torch.device('cuda:0')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Umbral de confianza para las detecciones\n",
        "detection_threshold = 0.5\n",
        "\n",
        "# Iteramos sobre los resultados (archivos)\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas al dispositivo GPU\n",
        "    cards = result.to(device)\n",
        "    # cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Filtrar detecciones con umbral de confianza inferior a 0.45\n",
        "    filtered_cards = [box for box in result.boxes if box.conf.item() >= detection_threshold]\n",
        "\n",
        "    # Procesamos cada carta detectada\n",
        "    for card in filtered_cards:\n",
        "        # Obtenemos el nombre de la carta\n",
        "        # name = filtered_cards.names[int(card.boxes.cls)]\n",
        "        name = cards.names[int(card.cls)]\n",
        "\n",
        "        # Separamos el número y el palo de la carta\n",
        "        if len(name) == 3:      # (Carta negra. Ejemplo 10E - 11E - 12B )\n",
        "            num = name[0] + name[1]  # número de la carta negra\n",
        "            palo = name[2]           # palo de la carta\n",
        "        elif len(name) == 2:                   # (Carta blanca. Ejemplo xO - xC - xE - xB )\n",
        "            num = name[0]            # número de la carta\n",
        "            palo = name[1]           # palo de la carta\n",
        "        else:\n",
        "            num = name[0]            # número del comodín\n",
        "            palo = 'N/A'             # palo del comodín\n",
        "\n",
        "        # Comprobamos si la carta es inválida\n",
        "        if num in ['8', '9', 'J']:\n",
        "            invalid_cards += 1\n",
        "\n",
        "        # Agregamos la carta al diccionario correspondiente\n",
        "        if palo in card_types:\n",
        "            card_types[palo].append(num)\n",
        "\n",
        "\n",
        "    # Comprobar si la cantidad de cartas es 3\n",
        "    if len(filtered_cards) != 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido.\\n')\n",
        "        envido = 0  # Aseguramos que envido tenga un valor\n",
        "        palo = 'N/A'  # Aseguramos que palo tenga un valor\n",
        "\n",
        "    # 3 cartas en la detección\n",
        "    else:\n",
        "        # Inicializamos la variable palo\n",
        "        palo = 'N/A'\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "            envido = 0\n",
        "            palo = 'N/A'\n",
        "\n",
        "        # Si no hay cartas inválidas, calculamos el envido\n",
        "        else:\n",
        "            # Iteramos en el diccionario - Key = palos / Value: números\n",
        "            for key, value in card_types.items():\n",
        "\n",
        "                # Dos cartas del mismo palo\n",
        "                if len(value) == 2:\n",
        "                    palo = key\n",
        "                    for num in value:\n",
        "                            if num not in ['10', '11', '12']:\n",
        "                                envido += int(num)\n",
        "\n",
        "                # Tres cartas del mismo palo\n",
        "                elif len(value) == 3:\n",
        "                        print('Mano con Flor.\\n')\n",
        "                        palo = key\n",
        "                        filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "\n",
        "                        # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                        if len(filtered_values) >= 2:\n",
        "                            largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "                            for num in largest_values:\n",
        "                                envido += int(num)\n",
        "                        elif len(filtered_values) == 1:\n",
        "                            envido += int(filtered_values[0])\n",
        "                        else:\n",
        "                            envido = 20     # Valor trivial ya declarado\n",
        "                else:\n",
        "                    envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido >= 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,       # Puntos de envido\n",
        "            'figure': palo          # Palo\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time['gpu'] = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "# print(f'Tiempo de ejecución: {execution_time['cpu']:.2f} segundos')\n",
        "print(f\"Tiempo de ejecución: {execution_time['gpu']:.2f} segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwH2UlYOu4uZ",
        "outputId": "5d083849-eee8-44fe-c9ba-d94bb9837132"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 3549.9ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 2431.2ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 2665.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 2463.3ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 3362.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 3386.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 2475.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 2520.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 2494.7ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 3593.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 3118.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 2643.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 2377.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 2484.2ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 4897.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 2455.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 2498.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 2458.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 2705.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 3981.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 2451.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 2426.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 2475.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 2728.2ms\n",
            "Mano con Flor.\n",
            "\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 3874.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 2462.1ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 2477.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 2471.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 2947.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 3679.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 2457.4ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 2464.5ms\n",
            "Speed: 4.8ms preprocess, 2858.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "El modelo está utilizando la CPU.\n",
            "Tiempo de ejecución: 100.84 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### V1"
      ],
      "metadata": {
        "id": "4B6XtCusu1dt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prcIq_tjUgGw",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cuda:0')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Procesamos los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,\n",
        "            'figure': type\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_gpu = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_gpu:.2f} segundos')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "FglvzTrXhkYt"
      },
      "source": [
        "### 4.3. *Inferencia con GPU - Con TensorRT*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### V0"
      ],
      "metadata": {
        "id": "fW4jcpCcwQnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "model = YOLO(model_path_tensor, task='detect')\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Umbral de confianza para las detecciones\n",
        "detection_threshold = 0.5\n",
        "\n",
        "# Iteramos sobre los resultados (archivos)\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas al dispositivo GPU\n",
        "    cards = result.to(device)\n",
        "    # cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Filtrar detecciones con umbral de confianza inferior a 0.45\n",
        "    filtered_cards = [box for box in result.boxes if box.conf.item() >= detection_threshold]\n",
        "\n",
        "    # Procesamos cada carta detectada\n",
        "    for card in filtered_cards:\n",
        "        # Obtenemos el nombre de la carta\n",
        "        # name = filtered_cards.names[int(card.boxes.cls)]\n",
        "        name = cards.names[int(card.cls)]\n",
        "\n",
        "        # Separamos el número y el palo de la carta\n",
        "        if len(name) == 3:      # (Carta negra. Ejemplo 10E - 11E - 12B )\n",
        "            num = name[0] + name[1]  # número de la carta negra\n",
        "            palo = name[2]           # palo de la carta\n",
        "        elif len(name) == 2:                   # (Carta blanca. Ejemplo xO - xC - xE - xB )\n",
        "            num = name[0]            # número de la carta\n",
        "            palo = name[1]           # palo de la carta\n",
        "        else:\n",
        "            num = name[0]            # número del comodín\n",
        "            palo = 'N/A'             # palo del comodín\n",
        "\n",
        "        # Comprobamos si la carta es inválida\n",
        "        if num in ['8', '9', 'J']:\n",
        "            invalid_cards += 1\n",
        "\n",
        "        # Agregamos la carta al diccionario correspondiente\n",
        "        if palo in card_types:\n",
        "            card_types[palo].append(num)\n",
        "\n",
        "\n",
        "    # Comprobar si la cantidad de cartas es 3\n",
        "    if len(filtered_cards) != 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido.\\n')\n",
        "        envido = 0  # Aseguramos que envido tenga un valor\n",
        "        palo = 'N/A'  # Aseguramos que palo tenga un valor\n",
        "\n",
        "    # 3 cartas en la detección\n",
        "    else:\n",
        "        # Inicializamos la variable palo\n",
        "        palo = 'N/A'\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "            envido = 0\n",
        "            palo = 'N/A'\n",
        "\n",
        "        # Si no hay cartas inválidas, calculamos el envido\n",
        "        else:\n",
        "            # Iteramos en el diccionario - Key = palos / Value: números\n",
        "            for key, value in card_types.items():\n",
        "\n",
        "                # Dos cartas del mismo palo\n",
        "                if len(value) == 2:\n",
        "                    palo = key\n",
        "                    for num in value:\n",
        "                            if num not in ['10', '11', '12']:\n",
        "                                envido += int(num)\n",
        "\n",
        "                # Tres cartas del mismo palo\n",
        "                elif len(value) == 3:\n",
        "                        print('Mano con Flor.\\n')\n",
        "                        palo = key\n",
        "                        filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "\n",
        "                        # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                        if len(filtered_values) >= 2:\n",
        "                            largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "                            for num in largest_values:\n",
        "                                envido += int(num)\n",
        "                        elif len(filtered_values) == 1:\n",
        "                            envido += int(filtered_values[0])\n",
        "                        else:\n",
        "                            envido = 20     # Valor trivial ya declarado\n",
        "                else:\n",
        "                    envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido >= 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,       # Puntos de envido\n",
        "            'figure': palo          # Palo\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time['rt'] = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "# print(f'Tiempo de ejecución: {execution_time['cpu']:.2f} segundos')\n",
        "print(f\"Tiempo de ejecución: {execution_time['rt']:.2f} segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFFsNtYdwSOm",
        "outputId": "fc6393ff-fc7d-415d-d7c6-899eefff6a3d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx for ONNX Runtime inference...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime'] not found, attempting AutoUpdate...\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 22.2 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 100.8 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 150.5 MB/s eta 0:00:00\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 5.9s, installed 1 package: ['onnxruntime']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x640 1 4O, 1 11C, 2809.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x640 1 1C, 1 2B, 1 5C, 2772.9ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x640 1 1C, 1 2B, 2796.4ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x640 1 3B, 1 6B, 1 7E, 4148.1ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x640 1 3B, 1 6B, 1 7E, 1 J, 3012.1ms\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x640 1 6B, 1 7E, 2760.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x640 1 3B, 2748.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x640 1 8O, 1 9O, 3519.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x640 1 3O, 1 8O, 1 9O, 3701.2ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x640 1 1O, 1 10C, 2763.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x640 1 1O, 2765.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x640 1 6E, 1 8B, 1 9B, 4124.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x640 1 8B, 7565.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x640 1 8C, 1 9C, 1 9E, 2775.9ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x640 1 3E, 1 4E, 3099.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x640 1 3E, 4122.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x640 1 11E, 1 12E, 2774.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x640 1 5E, 1 11O, 2751.1ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x640 1 4O, 1 12B, 2777.4ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x640 1 4O, 1 10E, 4709.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x640 1 2C, 3541.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x640 1 1E, 1 6C, 3631.4ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x640 1 2O, 1 7C, 2914.4ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x640 1 1B, 1 4B, 1 7B, 4315.1ms\n",
            "Mano con Flor.\n",
            "\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x640 1 7O, 1 10B, 2778.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x640 2 5Os, 1 10B, 2796.5ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x640 2 5Os, 1 6O, 1 10B, 2768.1ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x640 1 7C, 1 12O, 4231.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x640 1 6O, 3027.7ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x640 1 1B, 1 3C, 2765.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 640x640 1 5B, 2766.9ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x640 1 10O, 1 11B, 1 12C, 3832.7ms\n",
            "Speed: 5.9ms preprocess, 3370.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "El modelo está utilizando la CPU.\n",
            "Tiempo de ejecución: 135.22 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### V1"
      ],
      "metadata": {
        "id": "R7gY9vikwOLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "model = YOLO(model_path_tensor, task='detect')\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Procesamos los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,\n",
        "            'figure': type\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_rt = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_rt:.2f} segundos')"
      ],
      "metadata": {
        "id": "uBWN7IidPwB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4. *Comparativa de Inferencias*"
      ],
      "metadata": {
        "id": "HaokfCNTtD_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparación de los tiempos de ejecución\n",
        "print(\"Comparación de Tiempos de Ejecución:\")\n",
        "print(f\"Tiempo de ejecución (CPU): {execution_time['cpu']:.2f} segundos\")\n",
        "print(f\"Tiempo de ejecución (GPU): {execution_time['gpu']:.2f} segundos\")\n",
        "print(f\"Tiempo de ejecución (TensorRT): {execution_time['rt']:.2f} segundos\")"
      ],
      "metadata": {
        "id": "hLdMESYatKC3",
        "outputId": "a009291b-e2ac-43dd-e9bd-aae841f25e1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de Tiempos de Ejecución:\n",
            "Tiempo de ejecución (CPU): 113.86 segundos\n",
            "Tiempo de ejecución (GPU): 100.84 segundos\n",
            "Tiempo de ejecución (TensorRT): 135.22 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "kTG_5YDThkYu"
      },
      "source": [
        "## 5. **Guardamos las imagenes con las predicciones**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "# model = YOLO(model_path)              # Con CPU\n",
        "model = YOLO(model_path).to(device)     # Con GPU (sin TensorRT)\n",
        "# model = YOLO(model_path_tensor)       # Con GPU (con TensorRT)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Directorio donde van a ir las deteciones\n",
        "detection_dir = f'{base_dir}/detections/'\n",
        "\n",
        "# Creamos el directorio si no existe\n",
        "os.makedirs(detection_dir, exist_ok=True)\n",
        "\n",
        "# Iteramos sobre los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Guardamos la detección\n",
        "    result.save(filename=f'{detection_dir}/{img_filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjIxN-B3FBTK",
        "outputId": "2801906a-b85e-4193-bbc5-be38ea01e27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 1805.6ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 1304.6ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 1376.4ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1357.8ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 1363.4ms\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 1334.7ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 1530.4ms\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 1962.9ms\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 1728.0ms\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 1383.8ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 1274.4ms\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 1267.8ms\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 1309.7ms\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 1302.1ms\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 1334.6ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 1898.2ms\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 1928.7ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 1320.6ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 1315.7ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 1325.5ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 1312.2ms\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 1302.8ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 1319.3ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 1888.1ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 1919.9ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 1328.3ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 1290.0ms\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 1305.3ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 1285.0ms\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 1272.7ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 1312.3ms\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 1656.7ms\n",
            "Speed: 4.2ms preprocess, 1456.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "vAkTjCfUhkYv"
      },
      "source": [
        "## 6. **Escritura del archivo envido.json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wc50R4WLhkYv"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(dets_dir, 'envido.json'), 'w') as jf:\n",
        "    json.dump(card_js_file, jf, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. **Exportar directorios**"
      ],
      "metadata": {
        "id": "TInWEVkuhqDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especifica la carpeta a comprimir y el nombre del archivo zip\n",
        "folder_path = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/out/detections'\n",
        "\n",
        "zip_name = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/out/detections.zip'\n",
        "\n",
        "# Crear el archivo zip\n",
        "shutil.make_archive(zip_name.replace('.zip', ''), 'zip', folder_path)\n",
        "\n",
        "print(f\"Archivo zip creado: {zip_name}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-28T11:07:07.173550Z",
          "iopub.execute_input": "2024-07-28T11:07:07.174541Z",
          "iopub.status.idle": "2024-07-28T11:07:10.239276Z",
          "shell.execute_reply.started": "2024-07-28T11:07:07.174505Z",
          "shell.execute_reply": "2024-07-28T11:07:10.238323Z"
        },
        "trusted": true,
        "id": "46C89uqlhqDD",
        "outputId": "272d4909-8ca1-4e13-8727-3907e135c1e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo zip creado: /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/out/detections.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar un archivo\n",
        "os.remove('/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/out/detections.zip')\n",
        "print(\"Eliminación completa!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-28T11:12:05.215285Z",
          "iopub.execute_input": "2024-07-28T11:12:05.216362Z",
          "iopub.status.idle": "2024-07-28T11:12:05.300249Z",
          "shell.execute_reply.started": "2024-07-28T11:12:05.216325Z",
          "shell.execute_reply": "2024-07-28T11:12:05.299310Z"
        },
        "trusted": true,
        "id": "DpfCoSY6hqDE",
        "outputId": "7c7bede8-9f28-4681-edb9-24607a98d706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eliminación completa!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar un directorio y todo su contenido\n",
        "shutil.rmtree('/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/out/detections')\n",
        "print(\"Eliminación completa!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-28T11:16:32.995292Z",
          "iopub.execute_input": "2024-07-28T11:16:32.995705Z",
          "iopub.status.idle": "2024-07-28T11:16:33.033287Z",
          "shell.execute_reply.started": "2024-07-28T11:16:32.995674Z",
          "shell.execute_reply": "2024-07-28T11:16:33.032382Z"
        },
        "trusted": true,
        "id": "018JUVNUhqDF",
        "outputId": "71a16335-c8fa-468a-de6e-a0b93b9cf2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Eliminación completa!\n",
          "output_type": "stream"
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fHADhl4_hkYp",
        "FglvzTrXhkYt",
        "kTG_5YDThkYu",
        "vAkTjCfUhkYv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}