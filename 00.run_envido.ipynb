{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUKX__a1UgGt"
      },
      "source": [
        "# **TUIA - Procesamiento de Imágenes y Visión por Computadora (IA52)**\n",
        "# **Trabajo Práctico Final**\n",
        "### **Ejercicio 4 - Evaluación**\n",
        "<br>\n",
        "\n",
        "### *Alumno: Miguel Mussi*\n",
        "### *Año: 2024*\n",
        "\n",
        "---------------------\n",
        "## **Tabla de contenidos**\n",
        "1.   [**Librerías**](#)\n",
        "2.   [**Ajustes Iniciales**](#)\n",
        "3.   [**Optimización de inferencia**](#)\n",
        "4.   [**Verificamos si los Bounding Boxes estan dentro del límite de la imagen**](#)\n",
        "        1.   [*Inferencia con CPU*](#)\n",
        "        2.   [*Inferencia con GPU - Sin TensorRT*](#)\n",
        "        3.   [*Inferencia con GPU - Con TensorRT*](#)\n",
        "5.   [**Guardamos las imagenes con las predicciones**](#)\n",
        "6.   [**Escritura del archivo envido.json**](#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "I9JftkdJhkYQ"
      },
      "source": [
        "## 1. **Librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OeICo45_hkYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775de6f9-cf63-4005-fa98-02044a840931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.68)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjbG0RCXkgCx",
        "outputId": "a4ee2453-2e16-46fa-953b-6812e3ce5ed6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "IcIqnviJrXGm",
        "outputId": "b657659e-560f-4901-bc98-95d9870ca562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZxlBx8OXUgGu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Z5wXHxYThkYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc77dfd7-4a94-485a-8d53-de63c0d90f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "MfZDDGtnp7zA",
        "outputId": "0997a4a9-5b41-442c-a021-d70db4522565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzf_37QPUgGu",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 2. **Ajustes Iniciales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LrsYEZXHUgGv"
      },
      "outputs": [],
      "source": [
        "# Nombre del alumno\n",
        "student_name = 'miguel_mussi'\n",
        "\n",
        "# Ruta al archivo de pesos\n",
        "model_path = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.pt'\n",
        "model_path_tensor = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx'\n",
        "\n",
        "# Ruta al directorio que contiene las imagenes\n",
        "imgs_dir = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val'\n",
        "\n",
        "# Ruta al directorio de destino de las detecciones\n",
        "base_dir = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/out'\n",
        "dets_dir = os.path.join(base_dir, student_name)\n",
        "\n",
        "# Seteo de tiempos de ejecución\n",
        "execution_time_cpu = 0\n",
        "execution_time_gpu = 0\n",
        "execution_time_rt = 0\n",
        "\n",
        "# Reestablecimiento del directorio de destino (eliminacion)\n",
        "if os.path.exists(dets_dir):\n",
        "    shutil.rmtree(dets_dir)\n",
        "os.makedirs(dets_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0pBqm9G3hkYd"
      },
      "source": [
        "## 3. **Optimización de inferencia**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportamos el modelo como tensor"
      ],
      "metadata": {
        "id": "W5hfjGjFRDsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Lo exportamos como un tensor para utilizar tensorRT con la GPU\n",
        "model.export(format='onnx', imgsz=640, dynamic=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "VNAwXVLhDeT7",
        "outputId": "4af54ad0-bfb5-4415-b538-c83ae4c08825"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.68 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 268 layers, 43,644,387 parameters, 0 gradients, 165.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 53, 8400) (83.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 5.7s, saved as '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx' (166.6 MB)\n",
            "\n",
            "Export complete (13.9s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx imgsz=640 data=/kaggle/working/dataset.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Dispositivo del modelo: {next(model.parameters()).device}')"
      ],
      "metadata": {
        "id": "fCS2bG2MqdOY",
        "outputId": "726fb743-93bb-4188-882d-a59572728d78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo del modelo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Usando el dispositivo: {device}')"
      ],
      "metadata": {
        "id": "lBTdQzr2qpaX",
        "outputId": "8b4f2131-1fd4-48c8-95ab-d7ac04bef6fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando el dispositivo: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEvz0ZGdUgGw",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 4. **Inferencia sobre las imágenes y cálculamos el envido**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "wY0if1KUhkYn"
      },
      "source": [
        "### 4.1. *Inferencia con CPU*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cpu')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Iteramos sobre los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,       # Puntos de envido\n",
        "            'figure': type          # Palo\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_cpu = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_cpu:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXn2DkgfEcQf",
        "outputId": "ff939dca-aeed-4aa1-ca6e-1e3d7457e8aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 1922.2ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 2452.7ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 2911.4ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1912.1ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 1886.1ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 1881.8ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 2103.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 3031.0ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 2317.3ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 1860.8ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 1847.5ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 1904.6ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 1953.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 2673.5ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 2483.1ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 1865.4ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 1926.1ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 1880.4ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 1823.5ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 2552.3ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 2460.7ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 1853.3ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 1833.1ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 1796.6ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 1843.3ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 2315.6ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 2578.7ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 1854.2ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 1910.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 1852.1ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 1851.5ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 2299.3ms\n",
            "Speed: 3.8ms preprocess, 2113.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "El modelo está utilizando la CPU.\n",
            "Tiempo de ejecución: 74.35 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "fHADhl4_hkYp"
      },
      "source": [
        "### 4.2. *Inferencia con GPU - Sin TensorRT*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "prcIq_tjUgGw",
        "scrolled": true,
        "outputId": "f414ea89-d927-46e7-ec4b-321f7eabc739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No CUDA GPUs are available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f130488e6daf>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Cargamos el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Ejecutamos la inferencia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \"\"\"\n\u001b[1;32m    886\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_pytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# reset predictor as device may have changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m  \u001b[0;31m# was str(self.device) i.e. device(type='cuda', index=0) -> 'cuda:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAn\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mBaseModel\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Detect()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDetect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# includes all Detect subclasses like Segment, Pose, OBB, WorldDetect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     )\n\u001b[0;32m-> 1159\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cuda:0')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Procesamos los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,\n",
        "            'figure': type\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_gpu = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_gpu:.2f} segundos')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "FglvzTrXhkYt"
      },
      "source": [
        "### 4.3. *Inferencia con GPU - Con TensorRT*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "model = YOLO(model_path_tensor, task='detect')\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Procesamos los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,\n",
        "            'figure': type\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_rt = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_rt:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBWN7IidPwB4",
        "outputId": "c9847dc6-acc1-472b-d817-0b77ddae1b67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx for ONNX Runtime inference...\n",
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x640 1 4O, 1 11C, 2189.2ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x640 1 1C, 1 2B, 1 5C, 2770.5ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x640 1 1C, 1 2B, 2923.3ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x640 1 3B, 1 6B, 1 7E, 2202.7ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x640 1 3B, 1 6B, 1 7E, 1 J, 2438.6ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x640 1 6B, 1 7E, 2180.5ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x640 1 3B, 2581.0ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x640 1 8O, 1 9O, 3022.2ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x640 1 3O, 1 8O, 1 9O, 2351.9ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x640 1 1O, 1 10C, 3264.8ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x640 1 1O, 3132.0ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x640 1 6E, 1 8B, 1 9B, 5212.8ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x640 1 8B, 2153.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x640 1 8C, 1 9C, 1 9E, 2198.2ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x640 1 3E, 1 4E, 2150.1ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x640 1 3E, 2404.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x640 1 11E, 1 12E, 3293.1ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x640 1 5E, 1 11O, 2142.4ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x640 1 4O, 1 12B, 2141.9ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x640 1 4O, 1 10E, 2091.2ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x640 1 2C, 2098.2ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x640 1 1E, 1 6C, 3191.5ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x640 1 2O, 1 7C, 2330.5ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x640 1 1B, 1 4B, 1 7B, 2094.3ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x640 1 7O, 1 10B, 2101.0ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x640 2 5Os, 1 10B, 2146.9ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x640 2 5Os, 1 6O, 1 10B, 2611.6ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x640 1 7C, 1 12O, 2899.7ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x640 1 6O, 2137.4ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x640 1 1B, 1 3C, 2126.8ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 640x640 1 5B, 2113.7ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x640 1 10O, 1 11B, 1 12C, 2163.3ms\n",
            "Speed: 4.4ms preprocess, 2526.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "El modelo está utilizando la GPU.\n",
            "Tiempo de ejecución: 88.63 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparación de los tiempos de ejecución\n",
        "print(\"Comparación de Tiempos de Ejecución:\")\n",
        "print(f\"Tiempo de ejecución en CPU: {execution_time_cpu:.3f} segundos\")\n",
        "print(f\"Tiempo de ejecución en GPU (sin TensorRT): {execution_time_gpu:.3f} segundos\")\n",
        "print(f\"Tiempo de ejecución en GPU (con TensorRT): {execution_time_rt:.3f} segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7jEXv_1jzpZ",
        "outputId": "2b20c65c-9d5a-47d0-f04d-fb548c9e50e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de Tiempos de Ejecución:\n",
            "Tiempo de ejecución en CPU: 74.347 segundos\n",
            "Tiempo de ejecución en GPU (sin TensorRT): 0.000 segundos\n",
            "Tiempo de ejecución en GPU (con TensorRT): 88.631 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "kTG_5YDThkYu"
      },
      "source": [
        "## 5. **Guardamos las imagenes con las predicciones**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "# model = YOLO(model_path)              # Con CPU\n",
        "model = YOLO(model_path).to(device)     # Con GPU (sin TensorRT)\n",
        "# model = YOLO(model_path_tensor)       # Con GPU (con TensorRT)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Directorio donde van a ir las deteciones\n",
        "detection_dir = f'{base_dir}/detections/'\n",
        "\n",
        "# Creamos el directorio si no existe\n",
        "os.makedirs(detection_dir, exist_ok=True)\n",
        "\n",
        "# Iteramos sobre los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Guardamos la detección\n",
        "    result.save(filename=f'{detection_dir}/{img_filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjIxN-B3FBTK",
        "outputId": "521cc15c-ff70-4418-9138-741490af1b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 48.2ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 47.3ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 47.3ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 47.3ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 47.3ms\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 47.4ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 47.4ms\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 47.3ms\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 47.4ms\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 48.4ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 47.4ms\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 47.4ms\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 47.3ms\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 47.3ms\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 47.3ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 47.3ms\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 47.3ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 47.3ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 47.3ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 47.3ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 47.3ms\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 47.3ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 47.3ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 47.3ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 47.3ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 47.3ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 47.3ms\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 47.3ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 47.3ms\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 47.3ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 54.7ms\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 50.9ms\n",
            "Speed: 3.7ms preprocess, 47.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "vAkTjCfUhkYv"
      },
      "source": [
        "## 6. **Escritura del archivo envido.json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc50R4WLhkYv"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(dets_dir, 'envido.json'), 'w') as jf:\n",
        "    json.dump(card_js_file, jf, indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}