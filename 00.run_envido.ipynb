{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUKX__a1UgGt"
      },
      "source": [
        "# **TUIA - Procesamiento de Imágenes y Visión por Computadora (IA52)**\n",
        "# **Trabajo Práctico Final**\n",
        "### **Ejercicio 4 - Evaluación**\n",
        "<br>\n",
        "\n",
        "### *Alumno: Miguel Mussi*\n",
        "### *Año: 2024*\n",
        "\n",
        "---------------------\n",
        "## **Tabla de contenidos**\n",
        "1.   [**Librerías**](#)\n",
        "2.   [**Ajustes Iniciales**](#)\n",
        "3.   [**Optimización de inferencia**](#)\n",
        "4.   [**Verificamos si los Bounding Boxes estan dentro del límite de la imagen**](#)\n",
        "        1.   [*Inferencia con CPU*](#)\n",
        "        2.   [*Inferencia con GPU - Sin TensorRT*](#)\n",
        "        3.   [*Inferencia con GPU - Con TensorRT*](#)\n",
        "        4.   [*Comparativa de Inferencias*](#)\n",
        "5.   [**Guardamos las imagenes con las predicciones**](#)\n",
        "6.   [**Escritura del archivo envido.json**](#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "I9JftkdJhkYQ"
      },
      "source": [
        "## 1. **Librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OeICo45_hkYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6974421d-d676-4c1c-8104-06953d256377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.68)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjbG0RCXkgCx",
        "outputId": "90d852cb-ba7b-4a10-ffc5-6d808a669bb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZxlBx8OXUgGu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z5wXHxYThkYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c814156-191a-406a-f073-42949a04de9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzf_37QPUgGu",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 2. **Ajustes Iniciales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LrsYEZXHUgGv"
      },
      "outputs": [],
      "source": [
        "# Nombre del alumno\n",
        "student_name = 'miguel_mussi'\n",
        "\n",
        "# Ruta al archivo de pesos\n",
        "model_path = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.pt'\n",
        "model_path_tensor = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx'\n",
        "\n",
        "# Ruta al directorio que contiene las imagenes\n",
        "imgs_dir = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val'\n",
        "\n",
        "# Ruta al directorio de destino de las detecciones\n",
        "base_dir = '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/out'\n",
        "dets_dir = os.path.join(base_dir, student_name)\n",
        "\n",
        "# Reestablecimiento del directorio de destino (eliminacion)\n",
        "if os.path.exists(dets_dir):\n",
        "    shutil.rmtree(dets_dir)\n",
        "os.makedirs(dets_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seteo de tiempos de ejecución\n",
        "execution_time_cpu = 0\n",
        "execution_time_gpu = 0\n",
        "execution_time_rt = 0"
      ],
      "metadata": {
        "id": "yu8PD-WRsn2h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0pBqm9G3hkYd"
      },
      "source": [
        "## 3. **Optimización de inferencia**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "model = YOLO(model_path)"
      ],
      "metadata": {
        "id": "m0ucZWDi4uAt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportamos el modelo como tensor"
      ],
      "metadata": {
        "id": "W5hfjGjFRDsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo exportamos como un tensor para utilizar tensorRT con la GPU\n",
        "model.export(format='onnx', imgsz=640, dynamic=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "VNAwXVLhDeT7",
        "outputId": "ac00d6b8-834e-4cfa-a9af-cfada60d6e4e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.68 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.00GHz)\n",
            "Model summary (fused): 268 layers, 43,644,387 parameters, 0 gradients, 165.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 53, 8400) (83.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 4.7s, saved as '/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx' (166.6 MB)\n",
            "\n",
            "Export complete (11.6s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx imgsz=640 data=/kaggle/working/dataset.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/model/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "MfZDDGtnp7zA",
        "outputId": "ef67fd85-f582-4217-ca5f-2b082c6789c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Usando el dispositivo: {device}')"
      ],
      "metadata": {
        "id": "SI-9xjbZ4NWE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Dispositivo del modelo: {next(model.parameters()).device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CgC6KSX4Qki",
        "outputId": "6fe1689f-fe39-4df6-c851-87948e073f1f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo del modelo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wLIyEkD5-k6",
        "outputId": "ee1717ea-59cc-42c4-f04d-1d4c6ff9113e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device_id = 0  # El ID de dispositivo que deseas usar\n",
        "# if device_id < torch.cuda.device_count():\n",
        "#     device = torch.device(f'cuda:{device_id}')\n",
        "# else:\n",
        "#     raise AssertionError(\"Invalid device id\")"
      ],
      "metadata": {
        "id": "inEsYn2a5n7K"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_gpus = torch.cuda.device_count()\n",
        "print(f'Número de GPUs disponibles: {num_gpus}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLIDDDuT5ZZr",
        "outputId": "26540d6c-5ce2-4e8b-b095-fa7ffee2aa41"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de GPUs disponibles: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEvz0ZGdUgGw",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 4. **Inferencia sobre las imágenes y cálculamos el envido**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "wY0if1KUhkYn"
      },
      "source": [
        "### 4.1. *Inferencia con CPU*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cpu')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Iteramos sobre los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,       # Puntos de envido\n",
        "            'figure': type          # Palo\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_cpu = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_cpu:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXn2DkgfEcQf",
        "outputId": "0d35b6f9-aeec-4d10-dcb2-8b16595b38b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 1394.8ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 1294.4ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 1351.4ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1270.7ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 1303.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 1440.0ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 1814.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 1834.7ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 1272.5ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 1342.2ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 1327.5ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 1284.1ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 1723.5ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 1264.5ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 1570.8ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 1860.4ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 1646.4ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 1293.9ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 1297.4ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 1264.7ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 1336.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 1277.5ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 1296.5ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 1663.4ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 1891.6ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 1504.2ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 1259.4ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 1251.5ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 1261.1ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 1308.6ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 1303.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 1249.1ms\n",
            "Speed: 3.9ms preprocess, 1420.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "El modelo está utilizando la CPU.\n",
            "Tiempo de ejecución: 51.79 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "fHADhl4_hkYp"
      },
      "source": [
        "### 4.2. *Inferencia con GPU - Sin TensorRT*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "prcIq_tjUgGw",
        "scrolled": true,
        "outputId": "3086895a-db15-43d0-a7db-4420a5493db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 80.8ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 47.3ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 47.5ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 47.3ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 47.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 47.3ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 47.4ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 47.4ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 47.3ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 47.3ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 47.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 47.3ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 47.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 47.3ms\n",
            "No se puede calcular el envido por cartas inválidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 47.2ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 47.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 47.3ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 47.3ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 47.3ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 47.3ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 47.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 47.3ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 47.3ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 47.3ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 47.3ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 47.3ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 47.4ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 47.3ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 47.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 47.3ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 124.4ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 48.2ms\n",
            "Speed: 3.9ms preprocess, 50.8ms inference, 24.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "El modelo está utilizando la GPU.\n",
            "Tiempo de ejecución: 37.14 segundos\n"
          ]
        }
      ],
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cuda:0')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Procesamos los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,\n",
        "            'figure': type\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_gpu = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_gpu:.2f} segundos')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "FglvzTrXhkYt"
      },
      "source": [
        "### 4.3. *Inferencia con GPU - Con TensorRT*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "model = YOLO(model_path_tensor, task='detect')\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardará la información para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Procesamos los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inválidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es válida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el número y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # número de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # número de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inválida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inválidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inválidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores más altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,\n",
        "            'figure': type\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo después de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecución\n",
        "execution_time_rt = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecución\n",
        "if device.type == 'cuda': print('\\nEl modelo está utilizando la GPU.')\n",
        "else: print('\\nEl modelo está utilizando la CPU.')\n",
        "print(f'Tiempo de ejecución: {execution_time_rt:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "uBWN7IidPwB4",
        "outputId": "ae6011de-a78a-4bf7-a5ef-b58ba3842474"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Invalid device id",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ff1303fdebe6>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Ejecutamos la inferencia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Diccionario que guardará la información para el JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_cli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# only update args if predictor is already setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    303\u001b[0m         self.model = AutoBackend(\n\u001b[1;32m    304\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mdnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py\u001b[0m in \u001b[0;36mselect_device\u001b[0;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\\n\"\u001b[0m  \u001b[0;31m# bytes to MB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid device id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[name-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Invalid device id"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4. *Comparativa de Inferencias*"
      ],
      "metadata": {
        "id": "HaokfCNTtD_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparación de los tiempos de ejecución\n",
        "print(\"Comparación de Tiempos de Ejecución:\")\n",
        "print(f\"Tiempo de ejecución en CPU: {execution_time_cpu:.3f} segundos\")\n",
        "print(f\"Tiempo de ejecución en GPU (sin TensorRT): {execution_time_gpu:.3f} segundos\")\n",
        "print(f\"Tiempo de ejecución en GPU (con TensorRT): {execution_time_rt:.3f} segundos\")"
      ],
      "metadata": {
        "id": "hLdMESYatKC3",
        "outputId": "85895e83-68a8-4bda-a941-3aeafa790487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de Tiempos de Ejecución:\n",
            "Tiempo de ejecución en CPU: 51.515 segundos\n",
            "Tiempo de ejecución en GPU (sin TensorRT): 37.138 segundos\n",
            "Tiempo de ejecución en GPU (con TensorRT): 0.000 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "kTG_5YDThkYu"
      },
      "source": [
        "## 5. **Guardamos las imagenes con las predicciones**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "# model = YOLO(model_path)              # Con CPU\n",
        "model = YOLO(model_path).to(device)     # Con GPU (sin TensorRT)\n",
        "# model = YOLO(model_path_tensor)       # Con GPU (con TensorRT)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Directorio donde van a ir las deteciones\n",
        "detection_dir = f'{base_dir}/detections/'\n",
        "\n",
        "# Creamos el directorio si no existe\n",
        "os.makedirs(detection_dir, exist_ok=True)\n",
        "\n",
        "# Iteramos sobre los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Guardamos la detección\n",
        "    result.save(filename=f'{detection_dir}/{img_filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjIxN-B3FBTK",
        "outputId": "2801906a-b85e-4193-bbc5-be38ea01e27c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 1805.6ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 1304.6ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 1376.4ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1357.8ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 1363.4ms\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 1334.7ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 1530.4ms\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 1962.9ms\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 1728.0ms\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 1383.8ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 1274.4ms\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 1267.8ms\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 1309.7ms\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 1302.1ms\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 1334.6ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 1898.2ms\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 1928.7ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 1320.6ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 1315.7ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 1325.5ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 1312.2ms\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 1302.8ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 1319.3ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 1888.1ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 1919.9ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 1328.3ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 1290.0ms\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 1305.3ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 1285.0ms\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 1272.7ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 1312.3ms\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de Imág y Visión Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 1656.7ms\n",
            "Speed: 4.2ms preprocess, 1456.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "vAkTjCfUhkYv"
      },
      "source": [
        "## 6. **Escritura del archivo envido.json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wc50R4WLhkYv"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(dets_dir, 'envido.json'), 'w') as jf:\n",
        "    json.dump(card_js_file, jf, indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "fHADhl4_hkYp",
        "FglvzTrXhkYt",
        "kTG_5YDThkYu",
        "vAkTjCfUhkYv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}