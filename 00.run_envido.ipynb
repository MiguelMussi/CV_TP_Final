{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUKX__a1UgGt"
      },
      "source": [
        "# **TUIA - Procesamiento de Im√°genes y Visi√≥n por Computadora (IA52)**\n",
        "# **Trabajo Pr√°ctico Final**\n",
        "### **Ejercicio 4 - Evaluaci√≥n**\n",
        "<br>\n",
        "\n",
        "### *Alumno: Miguel Mussi*\n",
        "### *A√±o: 2024*\n",
        "\n",
        "---------------------\n",
        "## **Tabla de contenidos**\n",
        "1.   [**Librer√≠as**](#)\n",
        "2.   [**Ajustes Iniciales**](#)\n",
        "3.   [**Optimizaci√≥n de inferencia**](#)\n",
        "4.   [**Verificamos si los Bounding Boxes estan dentro del l√≠mite de la imagen**](#)\n",
        "        1.   [*Inferencia con CPU*](#)\n",
        "        2.   [*Inferencia con GPU - Sin TensorRT*](#)\n",
        "        3.   [*Inferencia con GPU - Con TensorRT*](#)\n",
        "        4.   [*Comparativa de Inferencias*](#)\n",
        "5.   [**Guardamos las imagenes con las predicciones**](#)\n",
        "6.   [**Escritura del archivo envido.json**](#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "I9JftkdJhkYQ"
      },
      "source": [
        "## 1. **Librer√≠as**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OeICo45_hkYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61331435-9bb9-4d93-c4fe-89e9a1d3e7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.70-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.70-py3-none-any.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m862.6/862.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.70 ultralytics-thop-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjbG0RCXkgCx",
        "outputId": "a6f6b56a-eb8d-45c4-b1fa-da12a809d36a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZxlBx8OXUgGu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z5wXHxYThkYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebf71f1-0d03-437c-83a4-86752afd2828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzf_37QPUgGu",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 2. **Ajustes Iniciales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LrsYEZXHUgGv"
      },
      "outputs": [],
      "source": [
        "# Nombre del alumno\n",
        "student_name = 'miguel_mussi'\n",
        "\n",
        "# Ruta al archivo de pesos\n",
        "model_path = '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/model/weights/best.pt'\n",
        "model_path_tensor = '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/model/weights/best.onnx'\n",
        "\n",
        "# Ruta al directorio que contiene las imagenes\n",
        "imgs_dir = '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val'\n",
        "\n",
        "# Ruta al directorio de destino de las detecciones\n",
        "base_dir = '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out'\n",
        "dets_dir = os.path.join(base_dir, student_name)\n",
        "\n",
        "# Reestablecimiento del directorio de destino (eliminacion)\n",
        "if os.path.exists(dets_dir):\n",
        "    shutil.rmtree(dets_dir)\n",
        "os.makedirs(dets_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seteo de tiempos de ejecuci√≥n\n",
        "execution_time = {'cpu': 0, 'gpu': 0, 'rt': 0}\n",
        "execution_time_cpu = 0\n",
        "execution_time_gpu = 0\n",
        "execution_time_rt = 0"
      ],
      "metadata": {
        "id": "yu8PD-WRsn2h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0pBqm9G3hkYd"
      },
      "source": [
        "## 3. **Optimizaci√≥n de inferencia**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "model = YOLO(model_path)"
      ],
      "metadata": {
        "id": "m0ucZWDi4uAt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportamos el modelo como tensor"
      ],
      "metadata": {
        "id": "W5hfjGjFRDsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo exportamos como un tensor para utilizar tensorRT con la GPU\n",
        "model.export(format='onnx', imgsz=640, dynamic=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "VNAwXVLhDeT7",
        "outputId": "4783bb65-6482-4e2e-c023-93e108231b84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.70 üöÄ Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.30GHz)\n",
            "Model summary (fused): 268 layers, 43,644,387 parameters, 0 gradients, 165.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/model/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 53, 8400) (83.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 15.1s, saved as '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/model/weights/best.onnx' (166.6 MB)\n",
            "\n",
            "Export complete (23.8s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/model/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/model/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/model/weights/best.onnx imgsz=640 data=/kaggle/working/dataset.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/model/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "MfZDDGtnp7zA",
        "outputId": "c74c43fe-59ba-4187-aa40-c57824f929d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Usando el dispositivo: {device}')"
      ],
      "metadata": {
        "id": "SI-9xjbZ4NWE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Dispositivo del modelo: {next(model.parameters()).device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CgC6KSX4Qki",
        "outputId": "6fe1689f-fe39-4df6-c851-87948e073f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo del modelo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wLIyEkD5-k6",
        "outputId": "ee1717ea-59cc-42c4-f04d-1d4c6ff9113e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device_id = 0  # El ID de dispositivo que deseas usar\n",
        "# if device_id < torch.cuda.device_count():\n",
        "#     device = torch.device(f'cuda:{device_id}')\n",
        "# else:\n",
        "#     raise AssertionError(\"Invalid device id\")"
      ],
      "metadata": {
        "id": "inEsYn2a5n7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_gpus = torch.cuda.device_count()\n",
        "print(f'N√∫mero de GPUs disponibles: {num_gpus}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLIDDDuT5ZZr",
        "outputId": "b2ad0851-e798-4a95-f8df-5ffa6b7923ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de GPUs disponibles: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEvz0ZGdUgGw",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 4. **Inferencia sobre las im√°genes y c√°lculamos el envido**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "wY0if1KUhkYn"
      },
      "source": [
        "### 4.1. *Inferencia con CPU*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### V0"
      ],
      "metadata": {
        "id": "NC5B2QM5yi-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cpu')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardar√° la informaci√≥n para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Umbral de confianza para las detecciones\n",
        "detection_threshold = 0.5\n",
        "\n",
        "# Iteramos sobre los resultados (archivos)\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inv√°lidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Filtrar detecciones con umbral de confianza inferior a 0.45\n",
        "    filtered_cards = [box for box in result.boxes if box.conf.item() >= detection_threshold]\n",
        "\n",
        "    # Procesamos cada carta detectada\n",
        "    for card in filtered_cards:\n",
        "        # Obtenemos el nombre de la carta\n",
        "        # name = filtered_cards.names[int(card.boxes.cls)]\n",
        "        name = cards.names[int(card.cls)]\n",
        "\n",
        "        # Separamos el n√∫mero y el palo de la carta\n",
        "        if len(name) == 3:      # (Carta negra. Ejemplo 10E - 11E - 12B )\n",
        "            num = name[0] + name[1]  # n√∫mero de la carta negra\n",
        "            palo = name[2]           # palo de la carta\n",
        "        elif len(name) == 2:                   # (Carta blanca. Ejemplo xO - xC - xE - xB )\n",
        "            num = name[0]            # n√∫mero de la carta\n",
        "            palo = name[1]           # palo de la carta\n",
        "        else:\n",
        "            num = name[0]            # n√∫mero del comod√≠n\n",
        "            palo = 'N/A'             # palo del comod√≠n\n",
        "\n",
        "        # Comprobamos si la carta es inv√°lida\n",
        "        if num in ['8', '9', 'J']:\n",
        "            invalid_cards += 1\n",
        "\n",
        "        # Agregamos la carta al diccionario correspondiente\n",
        "        if palo in card_types:\n",
        "            card_types[palo].append(num)\n",
        "\n",
        "\n",
        "    # Comprobar si la cantidad de cartas es 3\n",
        "    if len(filtered_cards) != 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido.\\n')\n",
        "        envido = 0  # Aseguramos que envido tenga un valor\n",
        "        palo = 'N/A'  # Aseguramos que palo tenga un valor\n",
        "\n",
        "    # 3 cartas en la detecci√≥n\n",
        "    else:\n",
        "        # Inicializamos la variable palo\n",
        "        palo = 'N/A'\n",
        "\n",
        "        # Si hay cartas inv√°lidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inv√°lidas\\n')\n",
        "            envido = 0\n",
        "            palo = 'N/A'\n",
        "\n",
        "        # Si no hay cartas inv√°lidas, calculamos el envido\n",
        "        else:\n",
        "            # Iteramos en el diccionario - Key = palos / Value: n√∫meros\n",
        "            for key, value in card_types.items():\n",
        "\n",
        "                # Dos cartas del mismo palo\n",
        "                if len(value) == 2:\n",
        "                    palo = key\n",
        "                    for num in value:\n",
        "                            if num not in ['10', '11', '12']:\n",
        "                                envido += int(num)\n",
        "\n",
        "                # Tres cartas del mismo palo\n",
        "                elif len(value) == 3:\n",
        "                        print('Mano con Flor.\\n')\n",
        "                        palo = key\n",
        "                        filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "\n",
        "                        # Filtramos los valores m√°s altos exceptuando los 10, 11 y 12\n",
        "                        if len(filtered_values) >= 2:\n",
        "                            largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "                            for num in largest_values:\n",
        "                                envido += int(num)\n",
        "                        elif len(filtered_values) == 1:\n",
        "                            envido += int(filtered_values[0])\n",
        "                        else:\n",
        "                            envido = 20     # Valor trivial ya declarado\n",
        "                else:\n",
        "                    envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido >= 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,       # Puntos de envido\n",
        "            'figure': palo          # Palo\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo despu√©s de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecuci√≥n\n",
        "execution_time_cpu = end_time - start_time\n",
        "execution_time['cpu'] = execution_time_cpu\n",
        "\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecuci√≥n\n",
        "if device.type == 'cuda': print('\\nEl modelo est√° utilizando la GPU.')\n",
        "else: print('\\nEl modelo est√° utilizando la CPU.')\n",
        "print(f'Tiempo de ejecuci√≥n: {execution_time_cpu:.2f} segundos')"
      ],
      "metadata": {
        "id": "wvNrpsDcfkxt",
        "outputId": "79c0683a-95b9-4afa-a58e-914a3ffd7796",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 2369.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 2378.4ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 2372.1ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 2631.6ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 3837.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 2382.3ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 2402.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 2377.1ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 2606.8ms\n",
            "No se puede calcular el envido por cartas inv√°lidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 3930.1ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 2555.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 2360.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 2346.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 2440.2ms\n",
            "No se puede calcular el envido por cartas inv√°lidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 3775.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 2693.7ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 2414.4ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 2377.9ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 2368.0ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 3528.4ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 3024.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 2355.7ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 2352.6ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 2349.3ms\n",
            "Mano con Flor.\n",
            "\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 3263.9ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 3500.2ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 2393.8ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 2348.1ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 2446.5ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 3482.2ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 3261.9ms\n",
            "La cantidad de cartas no permite calcular el envido.\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 2359.2ms\n",
            "Speed: 4.9ms preprocess, 2727.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "El modelo est√° utilizando la CPU.\n",
            "Tiempo de ejecuci√≥n: 96.97 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### v1"
      ],
      "metadata": {
        "id": "pfeVxNfSyfRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cpu')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardar√° la informaci√≥n para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Iteramos sobre los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inv√°lidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es v√°lida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "        envido = 0\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el n√∫mero y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # n√∫mero de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # n√∫mero de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inv√°lida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inv√°lidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inv√°lidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores m√°s altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,       # Puntos de envido\n",
        "            'figure': type          # Palo\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo despu√©s de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecuci√≥n\n",
        "execution_time_cpu = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecuci√≥n\n",
        "if device.type == 'cuda': print('\\nEl modelo est√° utilizando la GPU.')\n",
        "else: print('\\nEl modelo est√° utilizando la CPU.')\n",
        "print(f'Tiempo de ejecuci√≥n: {execution_time_cpu:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXn2DkgfEcQf",
        "outputId": "aa1e7ca3-73fd-4cfd-8d34-dde0091c3d37"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 2500.0ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 2379.1ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 2637.6ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 3789.7ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 2980.7ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 2417.4ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 2475.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 2476.8ms\n",
            "No se puede calcular el envido por cartas inv√°lidas\n",
            "\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 3946.9ms\n",
            "No se puede calcular el envido por cartas inv√°lidas\n",
            "\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 2733.6ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 2433.5ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 2466.9ms\n",
            "No se puede calcular el envido por cartas inv√°lidas\n",
            "\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 2524.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 3955.6ms\n",
            "No se puede calcular el envido por cartas inv√°lidas\n",
            "\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 2554.3ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 2514.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 2527.4ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 2679.8ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 3965.1ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 2488.2ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 2501.2ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 2526.7ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 3158.7ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 3657.7ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 2354.2ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 2414.9ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 2452.8ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 3286.4ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 3489.9ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 2459.0ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 2334.3ms\n",
            "La cantidad de cartas no permite calcular el envido\n",
            "\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 2463.8ms\n",
            "Speed: 4.7ms preprocess, 2798.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "El modelo est√° utilizando la CPU.\n",
            "Tiempo de ejecuci√≥n: 98.72 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "fHADhl4_hkYp"
      },
      "source": [
        "### 4.2. *Inferencia con GPU - Sin TensorRT*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "prcIq_tjUgGw",
        "scrolled": true,
        "outputId": "780052de-ec45-4b8b-e406-413cf223ee89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No CUDA GPUs are available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f130488e6daf>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Cargamos el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Ejecutamos la inferencia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \"\"\"\n\u001b[1;32m    886\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_pytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# reset predictor as device may have changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m  \u001b[0;31m# was str(self.device) i.e. device(type='cuda', index=0) -> 'cuda:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAn\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mBaseModel\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Detect()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDetect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# includes all Detect subclasses like Segment, Pose, OBB, WorldDetect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     )\n\u001b[0;32m-> 1159\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "device = torch.device('cuda:0')\n",
        "model = YOLO(model_path).to(device)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardar√° la informaci√≥n para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Procesamos los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inv√°lidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es v√°lida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el n√∫mero y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # n√∫mero de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # n√∫mero de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inv√°lida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inv√°lidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inv√°lidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores m√°s altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,\n",
        "            'figure': type\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo despu√©s de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecuci√≥n\n",
        "execution_time_gpu = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecuci√≥n\n",
        "if device.type == 'cuda': print('\\nEl modelo est√° utilizando la GPU.')\n",
        "else: print('\\nEl modelo est√° utilizando la CPU.')\n",
        "print(f'Tiempo de ejecuci√≥n: {execution_time_gpu:.2f} segundos')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "FglvzTrXhkYt"
      },
      "source": [
        "### 4.3. *Inferencia con GPU - Con TensorRT*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Marca de tiempo antes de la inferencia\n",
        "start_time = time.time()\n",
        "\n",
        "# Cargamos el modelo\n",
        "model = YOLO(model_path_tensor, task='detect')\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Diccionario que guardar√° la informaci√≥n para el JSON\n",
        "card_js_file = {}\n",
        "\n",
        "# Procesamos los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Contador de cartas inv√°lidas y envido\n",
        "    invalid_cards = 0\n",
        "    envido = 20\n",
        "\n",
        "    # Diccionario para almacenar los tipos de cartas\n",
        "    card_types = {'O': [], 'C': [], 'E': [], 'B': []}\n",
        "\n",
        "    # Obtenemos las cartas detectadas\n",
        "    cards = result.cpu()\n",
        "\n",
        "    # Guardamos las detecciones en un archivo de texto en formato YOLOv5\n",
        "    cards.save_txt(os.path.join(dets_dir, img_filename.replace('.jpg', '.txt')), save_conf=True)\n",
        "\n",
        "    # Comprobamos si la cantidad de cartas es v√°lida para calcular el envido\n",
        "    if len(cards) <= 1 or len(cards) > 3:\n",
        "        print('La cantidad de cartas no permite calcular el envido\\n')\n",
        "    else:\n",
        "        # Procesamos cada carta detectada\n",
        "        for card in cards:\n",
        "            name = cards.names[int(card.boxes.cls)]\n",
        "\n",
        "            # Separamos el n√∫mero y el palo de la carta\n",
        "            if len(name) == 3:\n",
        "                number = name[0] + name[1] # n√∫mero de la carta\n",
        "                type = name[2] # palo de la carta\n",
        "            else:\n",
        "                number = name[0] # n√∫mero de la carta\n",
        "                type = name[1] # palo de la carta\n",
        "\n",
        "            # Comprobamos si la carta es inv√°lida\n",
        "            if number in ['9', '8', 'J']:\n",
        "                invalid_cards += 1\n",
        "\n",
        "            # Agregamos la carta al diccionario correspondiente\n",
        "            if type in card_types:\n",
        "                card_types[type].append(number)\n",
        "\n",
        "        # Si hay cartas inv√°lidas, no se puede calcular el envido\n",
        "        if invalid_cards > 0:\n",
        "            print('No se puede calcular el envido por cartas inv√°lidas\\n')\n",
        "        else:\n",
        "            # Calculamos el envido basado en las cartas detectadas\n",
        "            for key, value in card_types.items():\n",
        "                if len(value) == 2:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in value:\n",
        "                        if number not in ['10', '11', '12']: # Ignoramos los 10, 11 y 12\n",
        "                            envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "                elif len(value) == 3:\n",
        "                    type = key # Guardamos el palo en otra variable para luego\n",
        "\n",
        "                    # Filtramos los valores m√°s altos exceptuando los 10, 11 y 12\n",
        "                    filtered_values = [x for x in value if x not in [10, 11, 12]]\n",
        "                    largest_values = sorted(filtered_values, reverse=True)[:2]\n",
        "\n",
        "                    # Calculamos el envido\n",
        "                    for number in largest_values:\n",
        "                        envido += int(number)\n",
        "                    if envido == 20:\n",
        "                        envido = 0\n",
        "\n",
        "    # Almacenamos los resultados del envido en el diccionario para el JSON\n",
        "    if envido != 20:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': envido,\n",
        "            'figure': type\n",
        "        }\n",
        "    else:\n",
        "        card_js_file[img_filename] = {\n",
        "            'total_cards': len(cards),\n",
        "            'cards': card_types,\n",
        "            'points': 0,\n",
        "            'figure': 'N/A'\n",
        "        }\n",
        "\n",
        "# Marca de tiempo despu√©s de la inferencia\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculamos el tiempo de ejecuci√≥n\n",
        "execution_time_rt = end_time - start_time\n",
        "\n",
        "# Mostramos que dispositivo se esta utilizando y el tiempo de ejecuci√≥n\n",
        "if device.type == 'cuda': print('\\nEl modelo est√° utilizando la GPU.')\n",
        "else: print('\\nEl modelo est√° utilizando la CPU.')\n",
        "print(f'Tiempo de ejecuci√≥n: {execution_time_rt:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "uBWN7IidPwB4",
        "outputId": "ae6011de-a78a-4bf7-a5ef-b58ba3842474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Invalid device id",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ff1303fdebe6>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Ejecutamos la inferencia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Diccionario que guardar√° la informaci√≥n para el JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_cli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# only update args if predictor is already setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    303\u001b[0m         self.model = AutoBackend(\n\u001b[1;32m    304\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mdnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py\u001b[0m in \u001b[0;36mselect_device\u001b[0;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\\n\"\u001b[0m  \u001b[0;31m# bytes to MB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid device id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[name-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Invalid device id"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4. *Comparativa de Inferencias*"
      ],
      "metadata": {
        "id": "HaokfCNTtD_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparaci√≥n de los tiempos de ejecuci√≥n\n",
        "print(\"Comparaci√≥n de Tiempos de Ejecuci√≥n:\")\n",
        "print(f\"Tiempo de ejecuci√≥n en CPU: {execution_time_cpu:.3f} segundos\")\n",
        "print(f\"Tiempo de ejecuci√≥n en GPU (sin TensorRT): {execution_time_gpu:.3f} segundos\")\n",
        "print(f\"Tiempo de ejecuci√≥n en GPU (con TensorRT): {execution_time_rt:.3f} segundos\")"
      ],
      "metadata": {
        "id": "hLdMESYatKC3",
        "outputId": "85895e83-68a8-4bda-a941-3aeafa790487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparaci√≥n de Tiempos de Ejecuci√≥n:\n",
            "Tiempo de ejecuci√≥n en CPU: 51.515 segundos\n",
            "Tiempo de ejecuci√≥n en GPU (sin TensorRT): 37.138 segundos\n",
            "Tiempo de ejecuci√≥n en GPU (con TensorRT): 0.000 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "kTG_5YDThkYu"
      },
      "source": [
        "## 5. **Guardamos las imagenes con las predicciones**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "# model = YOLO(model_path)              # Con CPU\n",
        "model = YOLO(model_path).to(device)     # Con GPU (sin TensorRT)\n",
        "# model = YOLO(model_path_tensor)       # Con GPU (con TensorRT)\n",
        "\n",
        "# Ejecutamos la inferencia\n",
        "results = model(imgs_dir, stream=True)\n",
        "\n",
        "# Directorio donde van a ir las deteciones\n",
        "detection_dir = f'{base_dir}/detections/'\n",
        "\n",
        "# Creamos el directorio si no existe\n",
        "os.makedirs(detection_dir, exist_ok=True)\n",
        "\n",
        "# Iteramos sobre los resultados\n",
        "for result in results:\n",
        "    # Obtenemos el nombre del archivo de imagen\n",
        "    img_filename = os.path.basename(result.path)\n",
        "\n",
        "    # Guardamos la detecci√≥n\n",
        "    result.save(filename=f'{detection_dir}/{img_filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjIxN-B3FBTK",
        "outputId": "2801906a-b85e-4193-bbc5-be38ea01e27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 4O, 1 11C, 1805.6ms\n",
            "image 2/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 1304.6ms\n",
            "image 3/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 1376.4ms\n",
            "image 4/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1357.8ms\n",
            "image 5/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 1 J, 1363.4ms\n",
            "image 6/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 1334.7ms\n",
            "image 7/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 1530.4ms\n",
            "image 8/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 8O, 1 9O, 1962.9ms\n",
            "image 9/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 8O, 1 9O, 1728.0ms\n",
            "image 10/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 1 1O, 1 10C, 1383.8ms\n",
            "image 11/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 1274.4ms\n",
            "image 12/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 6E, 1 8B, 1 9B, 1267.8ms\n",
            "image 13/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 1309.7ms\n",
            "image 14/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9C, 1 9E, 1302.1ms\n",
            "image 15/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 1334.6ms\n",
            "image 16/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 1898.2ms\n",
            "image 17/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 1 11E, 1 12E, 1928.7ms\n",
            "image 18/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 1320.6ms\n",
            "image 19/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 4O, 1 12B, 1315.7ms\n",
            "image 20/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 10E, 1325.5ms\n",
            "image 21/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 1312.2ms\n",
            "image 22/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 1302.8ms\n",
            "image 23/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 1 2O, 1 7C, 1319.3ms\n",
            "image 24/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 4B, 1 7B, 1888.1ms\n",
            "image 25/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 1919.9ms\n",
            "image 26/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 2 5Os, 1 10B, 1328.3ms\n",
            "image 27/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 2 5Os, 1 6O, 1 10B, 1290.0ms\n",
            "image 28/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 1305.3ms\n",
            "image 29/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 1 6O, 1285.0ms\n",
            "image 30/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 1272.7ms\n",
            "image 31/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 1312.3ms\n",
            "image 32/32 /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 1 10O, 1 11B, 1 12C, 1656.7ms\n",
            "Speed: 4.2ms preprocess, 1456.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "vAkTjCfUhkYv"
      },
      "source": [
        "## 6. **Escritura del archivo envido.json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wc50R4WLhkYv"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(dets_dir, 'envido.json'), 'w') as jf:\n",
        "    json.dump(card_js_file, jf, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. **Exportar directorio**"
      ],
      "metadata": {
        "id": "TInWEVkuhqDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especifica la carpeta a comprimir y el nombre del archivo zip\n",
        "folder_path = '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections'\n",
        "\n",
        "zip_name = '/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections.zip'\n",
        "\n",
        "# Crear el archivo zip\n",
        "shutil.make_archive(zip_name.replace('.zip', ''), 'zip', folder_path)\n",
        "\n",
        "print(f\"Archivo zip creado: {zip_name}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-28T11:07:07.173550Z",
          "iopub.execute_input": "2024-07-28T11:07:07.174541Z",
          "iopub.status.idle": "2024-07-28T11:07:10.239276Z",
          "shell.execute_reply.started": "2024-07-28T11:07:07.174505Z",
          "shell.execute_reply": "2024-07-28T11:07:10.238323Z"
        },
        "trusted": true,
        "id": "46C89uqlhqDD",
        "outputId": "272d4909-8ca1-4e13-8727-3907e135c1e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo zip creado: /content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar un archivo\n",
        "os.remove('/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections.zip')\n",
        "print(\"Eliminaci√≥n completa!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-28T11:12:05.215285Z",
          "iopub.execute_input": "2024-07-28T11:12:05.216362Z",
          "iopub.status.idle": "2024-07-28T11:12:05.300249Z",
          "shell.execute_reply.started": "2024-07-28T11:12:05.216325Z",
          "shell.execute_reply": "2024-07-28T11:12:05.299310Z"
        },
        "trusted": true,
        "id": "DpfCoSY6hqDE",
        "outputId": "7c7bede8-9f28-4681-edb9-24607a98d706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eliminaci√≥n completa!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar un directorio y todo su contenido\n",
        "shutil.rmtree('/content/drive/MyDrive/UNR/5 - Proc de ImaÃÅg y VisioÃÅn Comp. (IA52)/CV_TP_Final/data/out/detections')\n",
        "print(\"Eliminaci√≥n completa!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-28T11:16:32.995292Z",
          "iopub.execute_input": "2024-07-28T11:16:32.995705Z",
          "iopub.status.idle": "2024-07-28T11:16:33.033287Z",
          "shell.execute_reply.started": "2024-07-28T11:16:32.995674Z",
          "shell.execute_reply": "2024-07-28T11:16:33.032382Z"
        },
        "trusted": true,
        "id": "018JUVNUhqDF",
        "outputId": "71a16335-c8fa-468a-de6e-a0b93b9cf2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Eliminaci√≥n completa!\n",
          "output_type": "stream"
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fHADhl4_hkYp",
        "FglvzTrXhkYt",
        "kTG_5YDThkYu",
        "vAkTjCfUhkYv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}